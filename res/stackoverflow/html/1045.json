{
    "items": [
        {
            "tags": [
                "neural-network",
                "classification"
            ],
            "owner": {
                "reputation": 1,
                "user_id": 8438746,
                "user_type": "registered",
                "profile_image": "https://www.gravatar.com/avatar/58d01fa6a85c316f214c64db34f10b88?s=128&d=identicon&r=PG&f=1",
                "display_name": "Olli",
                "link": "https://stackoverflow.com/users/8438746/olli"
            },
            "is_answered": false,
            "view_count": 13,
            "answer_count": 0,
            "score": -1,
            "last_activity_date": 1524658231,
            "creation_date": 1524658231,
            "question_id": 50021998,
            "body_markdown": "Assume a timeseries **T_i**=(x_i,y_i) for i = 1:N.\r\n\r\nThis timeseries **T** consists of two different processes **Run** and **Tum**, e.g. **Run1_i** (i=1:a), **Tum1** (i=a+1:b), **Run2** (i=b+1:c), **Tum2** (i=c+1:d),... with \r\n*1 &lt; a &lt; b &lt; c &lt; d &lt;... &lt; N*\r\nwhere the procceses **Run** and **Tum** occur alternating. The length of the processes **Run** and **Tum** can be assumed to be &gt; 10. The complete process is then **T** = [**Run1** **Tum1** **Run2** **Tum2** ... ].\r\n\r\nAs there is a qualitative difference in the selection of the positions x_i and y_i in the processes **Run** and **Tum**, I would like to use a neural network to find the values a,b,c,d,... and quantify the corresponding states as **Run** or **Tum**.\r\n\r\nI got problems because this problems is not simply to classify a timeseries as **1** or **2**, because the process in complete consists of different subprocesses, which have to be detected in a first step.\r\n\r\nAny ideas how I can use a neural network to do this?\r\n\r\n",
            "link": "https://stackoverflow.com/questions/50021998/use-a-neural-network-to-classify-timeseries",
            "title": "Use a neural network to classify timeseries",
            "body": "<p>Assume a timeseries <strong>T_i</strong>=(x_i,y_i) for i = 1:N.</p>\n\n<p>This timeseries <strong>T</strong> consists of two different processes <strong>Run</strong> and <strong>Tum</strong>, e.g. <strong>Run1_i</strong> (i=1:a), <strong>Tum1</strong> (i=a+1:b), <strong>Run2</strong> (i=b+1:c), <strong>Tum2</strong> (i=c+1:d),... with \n<em>1 &lt; a &lt; b &lt; c &lt; d &lt;... &lt; N</em>\nwhere the procceses <strong>Run</strong> and <strong>Tum</strong> occur alternating. The length of the processes <strong>Run</strong> and <strong>Tum</strong> can be assumed to be > 10. The complete process is then <strong>T</strong> = [<strong>Run1</strong> <strong>Tum1</strong> <strong>Run2</strong> <strong>Tum2</strong> ... ].</p>\n\n<p>As there is a qualitative difference in the selection of the positions x_i and y_i in the processes <strong>Run</strong> and <strong>Tum</strong>, I would like to use a neural network to find the values a,b,c,d,... and quantify the corresponding states as <strong>Run</strong> or <strong>Tum</strong>.</p>\n\n<p>I got problems because this problems is not simply to classify a timeseries as <strong>1</strong> or <strong>2</strong>, because the process in complete consists of different subprocesses, which have to be detected in a first step.</p>\n\n<p>Any ideas how I can use a neural network to do this?</p>\n"
        },
        {
            "tags": [
                "node.js",
                "angular",
                "authentication",
                "login"
            ],
            "owner": {
                "reputation": 39,
                "user_id": 9258957,
                "user_type": "registered",
                "profile_image": "https://i.stack.imgur.com/mylyC.jpg?s=128&g=1",
                "display_name": "Platiplus",
                "link": "https://stackoverflow.com/users/9258957/platiplus"
            },
            "is_answered": false,
            "view_count": 23,
            "answer_count": 1,
            "score": 0,
            "last_activity_date": 1524658228,
            "creation_date": 1524656740,
            "question_id": 50021508,
            "body_markdown": "I&#39;m using a web API that receives http get requests and return json data coming from a mySQL database.\r\n\r\nThe http url return all users (http://localhost:3000/api/users)\r\n\r\nThe data arrives like this:\r\n\r\n[![enter image description here][1]][1]\r\n\r\n\r\n  [1]: https://i.stack.imgur.com/3itC1.png\r\n\r\nHow can I authenticate users with Angular 2+ using this data?",
            "link": "https://stackoverflow.com/questions/50021508/how-to-authenticate-users-through-angular-2-nodejs-api",
            "title": "How to authenticate users through Angular 2+ / NodeJS API",
            "body": "<p>I'm using a web API that receives http get requests and return json data coming from a mySQL database.</p>\n\n<p>The http url return all users (<a href=\"http://localhost:3000/api/users\" rel=\"nofollow noreferrer\">http://localhost:3000/api/users</a>)</p>\n\n<p>The data arrives like this:</p>\n\n<p><a href=\"https://i.stack.imgur.com/3itC1.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/3itC1.png\" alt=\"enter image description here\"></a></p>\n\n<p>How can I authenticate users with Angular 2+ using this data?</p>\n"
        },
        {
            "tags": [
                "tensorflow",
                "deep-learning",
                "tf-slim"
            ],
            "owner": {
                "reputation": 1,
                "user_id": 9691986,
                "user_type": "registered",
                "profile_image": "https://lh5.googleusercontent.com/-tMIb7hCeEHU/AAAAAAAAAAI/AAAAAAAAAC8/2X5f68JSoZY/photo.jpg?sz=128",
                "display_name": "nassima dif",
                "link": "https://stackoverflow.com/users/9691986/nassima-dif"
            },
            "is_answered": false,
            "view_count": 29,
            "answer_count": 0,
            "score": -3,
            "last_activity_date": 1524658223,
            "creation_date": 1524586029,
            "last_edit_date": 1524658223,
            "question_id": 50006304,
            "body_markdown": "I&#39;m trying to follow this tutorial [enter link description here][1]on transfer learning, I used my own dataset , and I&#39;m trying to use MobileNet instead to inception , the problem is in the MobileNet models there are 3 checkpoint files:\r\n`mobilenet_v1_0.5_128.ckpt.data-00000-of-00001\r\nmobilenet_v1_0.5_128.ckpt.index\r\nmobilenet_v1_0.5_128.ckpt.meta`\r\nwhen I use one of them got this Error :\r\n `\r\nNotFoundError (see above for traceback): Unsuccessful TensorSliceReader constructor: Failed to find any matching files for C://Users//hp//PycharmProjects//tfSlim/mobilenet_v1_0.5_128//mobilenet_v1_0.5_128.ckpt.meta\r\n\t[[Node: save/RestoreV2_139 = RestoreV2[dtypes=[DT_INT32], _device=&quot;/job:localhost/replica:0/task:0/device:CPU:0&quot;](_arg_save/Const_0_0, save/RestoreV2_139/tensor_names, save/RestoreV2_139/shape_and_slices)]]`\r\n\r\n\r\n  [1]: https://kwotsin.github.io/tech/2017/02/11/transfer-learning.html\n\n---\n\n            \r\n    \r\n    import tensorflow as tf\r\n    from tensorflow.contrib.framework.python.ops.variables import get_or_create_global_step\r\n    from tensorflow.python.platform import tf_logging as logging\r\n    #from inception_resnet_v2 import inception_resnet_v2, inception_resnet_v2_arg_scope\r\n    from models.research.slim.nets.mobilenet_v1 import mobilenet_v1, mobilenet_v1_arg_scope\r\n    import os\r\n    import time\r\n    import h5py\r\n    import numpy as np\r\n    \r\n    slim = tf.contrib.slim\r\n    \r\n    # ================ DATASET INFORMATION ======================\r\n    # State dataset directory where the tfrecord files are located\r\n    dataset_dir = &#39;C://Nassima//lymphoma//subs3&#39;\r\n    \r\n    # State where your log file is at. If it doesn&#39;t exist, create it.\r\n    log_dir = &#39;./log&#39;\r\n    \r\n    # State where your checkpoint file is\r\n    checkpoint_file = &#39;C://Users//hp//PycharmProjects//tfSlim/mobilenet_v1_0.5_128//mobilenet_v1_0.5_128.ckpt.meta&#39;\r\n    \r\n    \r\n    \r\n    # State the image size you&#39;re resizing your images to. We will use the default inception size of 299.\r\n    #image_size = 299\r\n    #image_size = 128\r\n    \r\n    # State the number of classes to predict:\r\n    num_classes = 3\r\n    # State the labels file and read it\r\n    labels_file = &#39;C://Nassima//lymphoma//subs3//labels.txt&#39;\r\n    labels = open(labels_file, &#39;r&#39;)\r\n    \r\n    # Create a dictionary to refer each label to their string name\r\n    labels_to_name = {}\r\n    for line in labels:\r\n        label, string_name = line.split(&#39;:&#39;)\r\n        string_name = string_name[:-1]  # Remove newline\r\n        labels_to_name[int(label)] = string_name\r\n    print(labels_to_name)\r\n    # Create the file pattern of your TFRecord files so that it could be recognized later on\r\n    &quot;&quot;&quot;\r\n    file_pattern = &#39;flowers_%s_*.tfrecord&#39;\r\n    &quot;&quot;&quot;\r\n    \r\n    # Create a dictionary that will help people understand your dataset better. This is required by the Dataset class later.\r\n    items_to_descriptions = {\r\n        &#39;image&#39;: &#39;A 3-channel RGB coloured lymphoma image that is either CLL, FL, MCL.&#39;,\r\n        &#39;label&#39;: &#39;A label that is as such -- 0:CLL, 1:FL, 2:MCL&#39;\r\n    }\r\n    \r\n    # ================= TRAINING INFORMATION ==================\r\n    # State the number of epochs to train\r\n    num_epochs = 1\r\n    \r\n    # State your batch size\r\n    #batch_size = 8\r\n    file_mean = &quot;C://Nassima//lymphoma//subs3//train//mean.hdf5&quot;\r\n    TRAINING_SET_SIZE = 41860\r\n    BATCH_SIZE = 128\r\n    IMAGE_SIZE =  144\r\n    IMAGE_RESIZE = 128\r\n    # Learning rate information and configuration (Up to you to experiment)\r\n    initial_learning_rate = 0.0002\r\n    learning_rate_decay_factor = 0.7\r\n    num_epochs_before_decay = 2\r\n    \r\n    def _int64_feature(value):\r\n        return tf.train.Feature(int64_list=tf.train.Int64List(value=value))\r\n    def _bytes_feature(value):\r\n        return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\r\n    class _image_object: # image object from protobuf\r\n        def __init__(self):\r\n            self.image = tf.Variable([], dtype=tf.string)\r\n            self.height = tf.Variable([], dtype=tf.int64)\r\n            self.width = tf.Variable([], dtype=tf.int64)\r\n            self.filename = tf.Variable([], dtype=tf.string)\r\n            self.label = tf.Variable([], dtype=tf.int32)\r\n    def read_and_decode(filename_queue, mean):\r\n        reader = tf.TFRecordReader()\r\n        _, serialized_example = reader.read(filename_queue)\r\n        features = tf.parse_single_example(serialized_example, features = {\r\n            &quot;image/encoded&quot;: tf.FixedLenFeature([], tf.string),\r\n            &quot;image/height&quot;: tf.FixedLenFeature([], tf.int64),\r\n            &quot;image/width&quot;: tf.FixedLenFeature([], tf.int64),\r\n            &quot;image/filename&quot;: tf.FixedLenFeature([], tf.string),\r\n            &quot;image/class/label&quot;: tf.FixedLenFeature([], tf.int64),})\r\n        image_encoded = features[&quot;image/encoded&quot;]\r\n        image_raw = tf.decode_raw(image_encoded, tf.float32)\r\n        image_object = _image_object()\r\n        #image_object.image = tf.image.resize_image_with_crop_or_pad(image_raw, IMAGE_SIZE, IMAGE_SIZE)\r\n        image_r = tf.reshape(image_raw, [IMAGE_SIZE, IMAGE_SIZE, 3])\r\n        #added\r\n        image_r = image_r - mean\r\n        image_r = tf.random_crop(image_r ,[IMAGE_RESIZE ,IMAGE_RESIZE ,3], seed = 0, name = None)\r\n        image_object.image = image_r\r\n        image_object.height = features[&quot;image/height&quot;]\r\n        image_object.width = features[&quot;image/width&quot;]\r\n        image_object.filename = features[&quot;image/filename&quot;]\r\n        image_object.label = tf.cast(features[&quot;image/class/label&quot;], tf.int64)\r\n        return image_object\r\n    def flower_input(mean, if_random = True, if_training = True):\r\n        if(if_training):\r\n            filenames = [os.path.join(dataset_dir, &quot;lymphoma_train_0000%d-of-00005.tfrecord&quot; % i) for i in range(0, 5)]\r\n        else:\r\n            filenames = [os.path.join(dataset_dir, &quot;lymphoma_validation_0000%d-of-00005.tfrecord&quot; % i) for i in range(0, 5)]\r\n        for f in filenames:\r\n            if not tf.gfile.Exists(f):\r\n                raise ValueError(&quot;Failed to find file: &quot; + f)\r\n        filename_queue = tf.train.string_input_producer(filenames)\r\n        image_object = read_and_decode(filename_queue, mean)\r\n        image = tf.image.per_image_standardization(image_object.image)\r\n    #    image = image_object.image\r\n    #    image = tf.image.adjust_gamma(tf.cast(image_object.image, tf.float32), gamma=1, gain=1) # Scale image to (0, 1)\r\n        filename = image_object.filename\r\n        label = image_object.label\r\n        if(if_random):\r\n            min_fraction_of_examples_in_queue = 0.4\r\n            min_queue_examples = int(TRAINING_SET_SIZE * min_fraction_of_examples_in_queue)\r\n            print(&quot;Filling queue with %d images before starting to train. &quot; &quot;This will take a few minutes.&quot; % min_queue_examples)\r\n            num_preprocess_threads = 1\r\n            image_batch, label_batch, filename_batch = tf.train.shuffle_batch(\r\n                [image, label, filename],\r\n                batch_size=BATCH_SIZE,\r\n                num_threads=num_preprocess_threads,\r\n                capacity=min_queue_examples + 3 * BATCH_SIZE,\r\n                min_after_dequeue=min_queue_examples)\r\n            return image_batch, label_batch, filename_batch\r\n        else:\r\n            image_batch, label_batch, filename_batch = tf.train.batch(\r\n                [image, label, filename],\r\n                batch_size=BATCH_SIZE,\r\n                num_threads=1)\r\n            return image_batch, label_batch, filename_batch\r\n    \r\n    &quot;&quot;&quot;\r\n    # ============== DATASET LOADING ======================\r\n    &quot;&quot;&quot;\r\n    \r\n    def run():\r\n        # Create the log directory here. Must be done here otherwise import will activate this unneededly.\r\n        if not os.path.exists(log_dir):\r\n            os.mkdir(log_dir)\r\n    \r\n        # ======================= TRAINING PROCESS =========================\r\n        # Now we start to construct the graph and build our model\r\n        with tf.Graph().as_default() as graph:\r\n            tf.logging.set_verbosity(tf.logging.INFO)  # Set the verbosity to INFO level\r\n            # ajouter le mean de l&#39;image\r\n            hdf5_file = h5py.File(file_mean, &quot;r&quot;)\r\n            # subtract the training mean\r\n            mm = hdf5_file[&quot;train_mean&quot;][0, ...]\r\n            mm = mm[np.newaxis, ...]\r\n            # Total number of samples\r\n            mean = tf.convert_to_tensor(mm, np.float32)\r\n            # First create the dataset and load one batch\r\n            images, labels, _ = flower_input(mean, if_random=True, if_training=True)\r\n            # Know the number steps to take before decaying the learning rate and batches per epoch\r\n            num_batches_per_epoch = int(TRAINING_SET_SIZE / BATCH_SIZE)\r\n            num_steps_per_epoch = num_batches_per_epoch  # Because one step is one batch processed\r\n            decay_steps = int(num_epochs_before_decay * num_steps_per_epoch)\r\n    \r\n            # Create the model inference\r\n            with slim.arg_scope(mobilenet_v1_arg_scope()):\r\n                logits, end_points = mobilenet_v1(images, num_classes= num_classes, is_training=True)\r\n    \r\n            # Define the scopes that you want to exclude for restoration\r\n            #exclude = [&#39;InceptionResnetV2/Logits&#39;, &#39;InceptionResnetV2/AuxLogits&#39;]\r\n            exclude = [&#39;MobilenetV1/Logits&#39;, &#39;MobilenetV1/AuxLogits&#39;]\r\n            #exclude = [&quot;MobilenetV1/Logits/Conv2d_1c_1x1&quot;]\r\n            #exclude = []\r\n            variables_to_restore = slim.get_variables_to_restore(exclude=exclude)\r\n    \r\n            # Perform one-hot-encoding of the labels (Try one-hot-encoding within the load_batch function!)\r\n            one_hot_labels = slim.one_hot_encoding(labels, num_classes)\r\n    \r\n            # Performs the equivalent to tf.nn.sparse_softmax_cross_entropy_with_logits but enhanced with checks\r\n            loss = tf.losses.softmax_cross_entropy(onehot_labels=one_hot_labels, logits=logits)\r\n            total_loss = tf.losses.get_total_loss()  # obtain the regularization losses as well\r\n    \r\n            # Create the global step for monitoring the learning_rate and training.\r\n            global_step = get_or_create_global_step()\r\n    \r\n            # Define your exponentially decaying learning rate\r\n            lr = tf.train.exponential_decay(\r\n                learning_rate=initial_learning_rate,\r\n                global_step=global_step,\r\n                decay_steps=decay_steps,\r\n                decay_rate=learning_rate_decay_factor,\r\n                staircase=True)\r\n    \r\n            # Now we can define the optimizer that takes on the learning rate\r\n            optimizer = tf.train.AdamOptimizer(learning_rate=lr)\r\n    \r\n            # Create the train_op.\r\n            train_op = slim.learning.create_train_op(total_loss, optimizer)\r\n    \r\n            # State the metrics that you want to predict. We get a predictions that is not one_hot_encoded.\r\n            predictions = tf.argmax(end_points[&#39;Predictions&#39;], 1)\r\n            probabilities = end_points[&#39;Predictions&#39;]\r\n            accuracy, accuracy_update = tf.contrib.metrics.streaming_accuracy(predictions, labels)\r\n            metrics_op = tf.group(accuracy_update, probabilities)\r\n    \r\n            # Now finally create all the summaries you need to monitor and group them into one summary op.\r\n            tf.summary.scalar(&#39;losses/Total_Loss&#39;, total_loss)\r\n            tf.summary.scalar(&#39;accuracy&#39;, accuracy)\r\n            tf.summary.scalar(&#39;learning_rate&#39;, lr)\r\n            my_summary_op = tf.summary.merge_all()\r\n    \r\n            # Now we need to create a training step function that runs both the train_op, metrics_op and updates the global_step concurrently.\r\n            def train_step(sess, train_op, global_step):\r\n                &#39;&#39;&#39;\r\n                Simply runs a session for the three arguments provided and gives a logging on the time elapsed for each global step\r\n                &#39;&#39;&#39;\r\n                # Check the time for each sess run\r\n                start_time = time.time()\r\n                total_loss, global_step_count, _ = sess.run([train_op, global_step, metrics_op])\r\n                time_elapsed = time.time() - start_time\r\n                # Run the logging to print some results\r\n                logging.info(&#39;global step %s: loss: %.4f (%.2f sec/step)&#39;, global_step_count, total_loss, time_elapsed)\r\n                return total_loss, global_step_count\r\n            # Now we create a saver function that actually restores the variables from a checkpoint file in a sess\r\n            saver = tf.train.Saver(variables_to_restore)\r\n            saver = tf.train.import_meta_graph(checkpoint_file)\r\n            #added\r\n            def restore_fn(sess):\r\n                return saver.restore(sess, &#39;C://Users//hp//PycharmProjects//tfSlim/mobilenet_v1_0.5_128//mobilenet_v1_0.5_128.ckpt&#39;)\r\n            # Define your supervisor for running a managed session. Do not run the summary_op automatically or else it will consume too much memory\r\n            sv = tf.train.Supervisor(logdir=log_dir, summary_op=None, init_fn=restore_fn)\r\n            # Run the managed session\r\n            with sv.managed_session() as sess:\r\n                for step in range(num_steps_per_epoch * num_epochs):\r\n                    # At the start of every epoch, show the vital information:\r\n                    if step % num_batches_per_epoch == 0:\r\n                        logging.info(&#39;Epoch %s/%s&#39;, step / num_batches_per_epoch + 1, num_epochs)\r\n                        learning_rate_value, accuracy_value = sess.run([lr, accuracy])\r\n                        logging.info(&#39;Current Learning Rate: %s&#39;, learning_rate_value)\r\n                        logging.info(&#39;Current Streaming Accuracy: %s&#39;, accuracy_value)\r\n    \r\n                        # optionally, print your logits and predictions for a sanity check that things are going fine.\r\n                        logits_value, probabilities_value, predictions_value, labels_value = sess.run(\r\n                            [logits, probabilities, predictions, labels])\r\n                        print\r\n                        &#39;logits: \\n&#39;, logits_value\r\n                        print\r\n                        &#39;Probabilities: \\n&#39;, probabilities_value\r\n                        print\r\n                        &#39;predictions: \\n&#39;, predictions_value\r\n                        print\r\n                        &#39;Labels:\\n:&#39;, labels_value\r\n                    # Log the summaries every 10 step.\r\n                    if step % 10 == 0:\r\n                        loss, _ = train_step(sess, train_op, sv.global_step)\r\n                        summaries = sess.run(my_summary_op)\r\n                        sv.summary_computed(sess, summaries)\r\n                    # If not, simply run the training step\r\n                    else:\r\n                        loss, _ = train_step(sess, train_op, sv.global_step)\r\n    \r\n                # We log the final training loss and accuracy\r\n                logging.info(&#39;Final Loss: %s&#39;, loss)\r\n                logging.info(&#39;Final Accuracy: %s&#39;, sess.run(accuracy))\r\n                # Once all the training has been done, save the log files and checkpoint model\r\n                logging.info(&#39;Finished training! Saving model to disk now.&#39;)\r\n                # saver.save(sess, &quot;./flowers_model.ckpt&quot;)\r\n                #sv.saver.save(sess, sv.save_path, global_step=sv.global_step)\r\n    \r\n   \r\n    \r\n    if __name__ == &#39;__main__&#39;:\r\n        run()\r\n and the error is \r\n\r\n    File &quot;C:/Users/hp/PycharmProjects/tfSlim/lympho_mobileNet/train_lymphoma2.py&quot;, line 272, in &lt;module&gt;\r\n        run()\r\n      File &quot;C:/Users/hp/PycharmProjects/tfSlim/lympho_mobileNet/train_lymphoma2.py&quot;, line 230, in run\r\n        sv = tf.train.Supervisor(logdir=log_dir, summary_op=None, init_fn=restore_fn)\r\n      File &quot;C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\supervisor.py&quot;, line 300, in __init__\r\n        self._init_saver(saver=saver)\r\n      File &quot;C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\supervisor.py&quot;, line 448, in _init_saver\r\n        saver = saver_mod.Saver()\r\n      File &quot;C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py&quot;, line 1218, in __init__\r\n        self.build()\r\n      File &quot;C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py&quot;, line 1227, in build\r\n        self._build(self._filename, build_save=True, build_restore=True)\r\n      File &quot;C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py&quot;, line 1263, in _build\r\n        build_save=build_save, build_restore=build_restore)\r\n      File &quot;C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py&quot;, line 729, in _build_internal\r\n        saveables = self._ValidateAndSliceInputs(names_to_saveables)\r\n      File &quot;C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py&quot;, line 582, in _ValidateAndSliceInputs\r\n        names_to_saveables = BaseSaverBuilder.OpListToDict(names_to_saveables)\r\n      File &quot;C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py&quot;, line 554, in OpListToDict\r\n        name)\r\n    ValueError: At least two variables have the same name: MobilenetV1/Conv2d_7_depthwise/BatchNorm/gamma\r\n\r\nI think because of the excluded layers or the instruction \r\n\r\n    tf.train.import_meta_graph(checkpoint_file)\r\n\r\n",
            "link": "https://stackoverflow.com/questions/50006304/transfer-learning-tersoflow",
            "title": "Transfer learning tersoflow",
            "body": "<p>I'm trying to follow this tutorial <a href=\"https://kwotsin.github.io/tech/2017/02/11/transfer-learning.html\" rel=\"nofollow noreferrer\">enter link description here</a>on transfer learning, I used my own dataset , and I'm trying to use MobileNet instead to inception , the problem is in the MobileNet models there are 3 checkpoint files:\n<code>mobilenet_v1_0.5_128.ckpt.data-00000-of-00001\nmobilenet_v1_0.5_128.ckpt.index\nmobilenet_v1_0.5_128.ckpt.meta</code>\nwhen I use one of them got this Error :\n <code>\nNotFoundError (see above for traceback): Unsuccessful TensorSliceReader constructor: Failed to find any matching files for C://Users//hp//PycharmProjects//tfSlim/mobilenet_v1_0.5_128//mobilenet_v1_0.5_128.ckpt.meta\n    [[Node: save/RestoreV2_139 = RestoreV2[dtypes=[DT_INT32], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_save/Const_0_0, save/RestoreV2_139/tensor_names, save/RestoreV2_139/shape_and_slices)]]</code></p>\n\n<hr>\n\n<pre><code>import tensorflow as tf\nfrom tensorflow.contrib.framework.python.ops.variables import get_or_create_global_step\nfrom tensorflow.python.platform import tf_logging as logging\n#from inception_resnet_v2 import inception_resnet_v2, inception_resnet_v2_arg_scope\nfrom models.research.slim.nets.mobilenet_v1 import mobilenet_v1, mobilenet_v1_arg_scope\nimport os\nimport time\nimport h5py\nimport numpy as np\n\nslim = tf.contrib.slim\n\n# ================ DATASET INFORMATION ======================\n# State dataset directory where the tfrecord files are located\ndataset_dir = 'C://Nassima//lymphoma//subs3'\n\n# State where your log file is at. If it doesn't exist, create it.\nlog_dir = './log'\n\n# State where your checkpoint file is\ncheckpoint_file = 'C://Users//hp//PycharmProjects//tfSlim/mobilenet_v1_0.5_128//mobilenet_v1_0.5_128.ckpt.meta'\n\n\n\n# State the image size you're resizing your images to. We will use the default inception size of 299.\n#image_size = 299\n#image_size = 128\n\n# State the number of classes to predict:\nnum_classes = 3\n# State the labels file and read it\nlabels_file = 'C://Nassima//lymphoma//subs3//labels.txt'\nlabels = open(labels_file, 'r')\n\n# Create a dictionary to refer each label to their string name\nlabels_to_name = {}\nfor line in labels:\n    label, string_name = line.split(':')\n    string_name = string_name[:-1]  # Remove newline\n    labels_to_name[int(label)] = string_name\nprint(labels_to_name)\n# Create the file pattern of your TFRecord files so that it could be recognized later on\n\"\"\"\nfile_pattern = 'flowers_%s_*.tfrecord'\n\"\"\"\n\n# Create a dictionary that will help people understand your dataset better. This is required by the Dataset class later.\nitems_to_descriptions = {\n    'image': 'A 3-channel RGB coloured lymphoma image that is either CLL, FL, MCL.',\n    'label': 'A label that is as such -- 0:CLL, 1:FL, 2:MCL'\n}\n\n# ================= TRAINING INFORMATION ==================\n# State the number of epochs to train\nnum_epochs = 1\n\n# State your batch size\n#batch_size = 8\nfile_mean = \"C://Nassima//lymphoma//subs3//train//mean.hdf5\"\nTRAINING_SET_SIZE = 41860\nBATCH_SIZE = 128\nIMAGE_SIZE =  144\nIMAGE_RESIZE = 128\n# Learning rate information and configuration (Up to you to experiment)\ninitial_learning_rate = 0.0002\nlearning_rate_decay_factor = 0.7\nnum_epochs_before_decay = 2\n\ndef _int64_feature(value):\n    return tf.train.Feature(int64_list=tf.train.Int64List(value=value))\ndef _bytes_feature(value):\n    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\nclass _image_object: # image object from protobuf\n    def __init__(self):\n        self.image = tf.Variable([], dtype=tf.string)\n        self.height = tf.Variable([], dtype=tf.int64)\n        self.width = tf.Variable([], dtype=tf.int64)\n        self.filename = tf.Variable([], dtype=tf.string)\n        self.label = tf.Variable([], dtype=tf.int32)\ndef read_and_decode(filename_queue, mean):\n    reader = tf.TFRecordReader()\n    _, serialized_example = reader.read(filename_queue)\n    features = tf.parse_single_example(serialized_example, features = {\n        \"image/encoded\": tf.FixedLenFeature([], tf.string),\n        \"image/height\": tf.FixedLenFeature([], tf.int64),\n        \"image/width\": tf.FixedLenFeature([], tf.int64),\n        \"image/filename\": tf.FixedLenFeature([], tf.string),\n        \"image/class/label\": tf.FixedLenFeature([], tf.int64),})\n    image_encoded = features[\"image/encoded\"]\n    image_raw = tf.decode_raw(image_encoded, tf.float32)\n    image_object = _image_object()\n    #image_object.image = tf.image.resize_image_with_crop_or_pad(image_raw, IMAGE_SIZE, IMAGE_SIZE)\n    image_r = tf.reshape(image_raw, [IMAGE_SIZE, IMAGE_SIZE, 3])\n    #added\n    image_r = image_r - mean\n    image_r = tf.random_crop(image_r ,[IMAGE_RESIZE ,IMAGE_RESIZE ,3], seed = 0, name = None)\n    image_object.image = image_r\n    image_object.height = features[\"image/height\"]\n    image_object.width = features[\"image/width\"]\n    image_object.filename = features[\"image/filename\"]\n    image_object.label = tf.cast(features[\"image/class/label\"], tf.int64)\n    return image_object\ndef flower_input(mean, if_random = True, if_training = True):\n    if(if_training):\n        filenames = [os.path.join(dataset_dir, \"lymphoma_train_0000%d-of-00005.tfrecord\" % i) for i in range(0, 5)]\n    else:\n        filenames = [os.path.join(dataset_dir, \"lymphoma_validation_0000%d-of-00005.tfrecord\" % i) for i in range(0, 5)]\n    for f in filenames:\n        if not tf.gfile.Exists(f):\n            raise ValueError(\"Failed to find file: \" + f)\n    filename_queue = tf.train.string_input_producer(filenames)\n    image_object = read_and_decode(filename_queue, mean)\n    image = tf.image.per_image_standardization(image_object.image)\n#    image = image_object.image\n#    image = tf.image.adjust_gamma(tf.cast(image_object.image, tf.float32), gamma=1, gain=1) # Scale image to (0, 1)\n    filename = image_object.filename\n    label = image_object.label\n    if(if_random):\n        min_fraction_of_examples_in_queue = 0.4\n        min_queue_examples = int(TRAINING_SET_SIZE * min_fraction_of_examples_in_queue)\n        print(\"Filling queue with %d images before starting to train. \" \"This will take a few minutes.\" % min_queue_examples)\n        num_preprocess_threads = 1\n        image_batch, label_batch, filename_batch = tf.train.shuffle_batch(\n            [image, label, filename],\n            batch_size=BATCH_SIZE,\n            num_threads=num_preprocess_threads,\n            capacity=min_queue_examples + 3 * BATCH_SIZE,\n            min_after_dequeue=min_queue_examples)\n        return image_batch, label_batch, filename_batch\n    else:\n        image_batch, label_batch, filename_batch = tf.train.batch(\n            [image, label, filename],\n            batch_size=BATCH_SIZE,\n            num_threads=1)\n        return image_batch, label_batch, filename_batch\n\n\"\"\"\n# ============== DATASET LOADING ======================\n\"\"\"\n\ndef run():\n    # Create the log directory here. Must be done here otherwise import will activate this unneededly.\n    if not os.path.exists(log_dir):\n        os.mkdir(log_dir)\n\n    # ======================= TRAINING PROCESS =========================\n    # Now we start to construct the graph and build our model\n    with tf.Graph().as_default() as graph:\n        tf.logging.set_verbosity(tf.logging.INFO)  # Set the verbosity to INFO level\n        # ajouter le mean de l'image\n        hdf5_file = h5py.File(file_mean, \"r\")\n        # subtract the training mean\n        mm = hdf5_file[\"train_mean\"][0, ...]\n        mm = mm[np.newaxis, ...]\n        # Total number of samples\n        mean = tf.convert_to_tensor(mm, np.float32)\n        # First create the dataset and load one batch\n        images, labels, _ = flower_input(mean, if_random=True, if_training=True)\n        # Know the number steps to take before decaying the learning rate and batches per epoch\n        num_batches_per_epoch = int(TRAINING_SET_SIZE / BATCH_SIZE)\n        num_steps_per_epoch = num_batches_per_epoch  # Because one step is one batch processed\n        decay_steps = int(num_epochs_before_decay * num_steps_per_epoch)\n\n        # Create the model inference\n        with slim.arg_scope(mobilenet_v1_arg_scope()):\n            logits, end_points = mobilenet_v1(images, num_classes= num_classes, is_training=True)\n\n        # Define the scopes that you want to exclude for restoration\n        #exclude = ['InceptionResnetV2/Logits', 'InceptionResnetV2/AuxLogits']\n        exclude = ['MobilenetV1/Logits', 'MobilenetV1/AuxLogits']\n        #exclude = [\"MobilenetV1/Logits/Conv2d_1c_1x1\"]\n        #exclude = []\n        variables_to_restore = slim.get_variables_to_restore(exclude=exclude)\n\n        # Perform one-hot-encoding of the labels (Try one-hot-encoding within the load_batch function!)\n        one_hot_labels = slim.one_hot_encoding(labels, num_classes)\n\n        # Performs the equivalent to tf.nn.sparse_softmax_cross_entropy_with_logits but enhanced with checks\n        loss = tf.losses.softmax_cross_entropy(onehot_labels=one_hot_labels, logits=logits)\n        total_loss = tf.losses.get_total_loss()  # obtain the regularization losses as well\n\n        # Create the global step for monitoring the learning_rate and training.\n        global_step = get_or_create_global_step()\n\n        # Define your exponentially decaying learning rate\n        lr = tf.train.exponential_decay(\n            learning_rate=initial_learning_rate,\n            global_step=global_step,\n            decay_steps=decay_steps,\n            decay_rate=learning_rate_decay_factor,\n            staircase=True)\n\n        # Now we can define the optimizer that takes on the learning rate\n        optimizer = tf.train.AdamOptimizer(learning_rate=lr)\n\n        # Create the train_op.\n        train_op = slim.learning.create_train_op(total_loss, optimizer)\n\n        # State the metrics that you want to predict. We get a predictions that is not one_hot_encoded.\n        predictions = tf.argmax(end_points['Predictions'], 1)\n        probabilities = end_points['Predictions']\n        accuracy, accuracy_update = tf.contrib.metrics.streaming_accuracy(predictions, labels)\n        metrics_op = tf.group(accuracy_update, probabilities)\n\n        # Now finally create all the summaries you need to monitor and group them into one summary op.\n        tf.summary.scalar('losses/Total_Loss', total_loss)\n        tf.summary.scalar('accuracy', accuracy)\n        tf.summary.scalar('learning_rate', lr)\n        my_summary_op = tf.summary.merge_all()\n\n        # Now we need to create a training step function that runs both the train_op, metrics_op and updates the global_step concurrently.\n        def train_step(sess, train_op, global_step):\n            '''\n            Simply runs a session for the three arguments provided and gives a logging on the time elapsed for each global step\n            '''\n            # Check the time for each sess run\n            start_time = time.time()\n            total_loss, global_step_count, _ = sess.run([train_op, global_step, metrics_op])\n            time_elapsed = time.time() - start_time\n            # Run the logging to print some results\n            logging.info('global step %s: loss: %.4f (%.2f sec/step)', global_step_count, total_loss, time_elapsed)\n            return total_loss, global_step_count\n        # Now we create a saver function that actually restores the variables from a checkpoint file in a sess\n        saver = tf.train.Saver(variables_to_restore)\n        saver = tf.train.import_meta_graph(checkpoint_file)\n        #added\n        def restore_fn(sess):\n            return saver.restore(sess, 'C://Users//hp//PycharmProjects//tfSlim/mobilenet_v1_0.5_128//mobilenet_v1_0.5_128.ckpt')\n        # Define your supervisor for running a managed session. Do not run the summary_op automatically or else it will consume too much memory\n        sv = tf.train.Supervisor(logdir=log_dir, summary_op=None, init_fn=restore_fn)\n        # Run the managed session\n        with sv.managed_session() as sess:\n            for step in range(num_steps_per_epoch * num_epochs):\n                # At the start of every epoch, show the vital information:\n                if step % num_batches_per_epoch == 0:\n                    logging.info('Epoch %s/%s', step / num_batches_per_epoch + 1, num_epochs)\n                    learning_rate_value, accuracy_value = sess.run([lr, accuracy])\n                    logging.info('Current Learning Rate: %s', learning_rate_value)\n                    logging.info('Current Streaming Accuracy: %s', accuracy_value)\n\n                    # optionally, print your logits and predictions for a sanity check that things are going fine.\n                    logits_value, probabilities_value, predictions_value, labels_value = sess.run(\n                        [logits, probabilities, predictions, labels])\n                    print\n                    'logits: \\n', logits_value\n                    print\n                    'Probabilities: \\n', probabilities_value\n                    print\n                    'predictions: \\n', predictions_value\n                    print\n                    'Labels:\\n:', labels_value\n                # Log the summaries every 10 step.\n                if step % 10 == 0:\n                    loss, _ = train_step(sess, train_op, sv.global_step)\n                    summaries = sess.run(my_summary_op)\n                    sv.summary_computed(sess, summaries)\n                # If not, simply run the training step\n                else:\n                    loss, _ = train_step(sess, train_op, sv.global_step)\n\n            # We log the final training loss and accuracy\n            logging.info('Final Loss: %s', loss)\n            logging.info('Final Accuracy: %s', sess.run(accuracy))\n            # Once all the training has been done, save the log files and checkpoint model\n            logging.info('Finished training! Saving model to disk now.')\n            # saver.save(sess, \"./flowers_model.ckpt\")\n            #sv.saver.save(sess, sv.save_path, global_step=sv.global_step)\n\n\n\nif __name__ == '__main__':\n    run()\n</code></pre>\n\n<p>and the error is </p>\n\n<pre><code>File \"C:/Users/hp/PycharmProjects/tfSlim/lympho_mobileNet/train_lymphoma2.py\", line 272, in &lt;module&gt;\n    run()\n  File \"C:/Users/hp/PycharmProjects/tfSlim/lympho_mobileNet/train_lymphoma2.py\", line 230, in run\n    sv = tf.train.Supervisor(logdir=log_dir, summary_op=None, init_fn=restore_fn)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\supervisor.py\", line 300, in __init__\n    self._init_saver(saver=saver)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\supervisor.py\", line 448, in _init_saver\n    saver = saver_mod.Saver()\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 1218, in __init__\n    self.build()\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 1227, in build\n    self._build(self._filename, build_save=True, build_restore=True)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 1263, in _build\n    build_save=build_save, build_restore=build_restore)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 729, in _build_internal\n    saveables = self._ValidateAndSliceInputs(names_to_saveables)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 582, in _ValidateAndSliceInputs\n    names_to_saveables = BaseSaverBuilder.OpListToDict(names_to_saveables)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 554, in OpListToDict\n    name)\nValueError: At least two variables have the same name: MobilenetV1/Conv2d_7_depthwise/BatchNorm/gamma\n</code></pre>\n\n<p>I think because of the excluded layers or the instruction </p>\n\n<pre><code>tf.train.import_meta_graph(checkpoint_file)\n</code></pre>\n"
        },
        {
            "tags": [
                "maven",
                "java-ee",
                "portlet"
            ],
            "owner": {
                "reputation": 52,
                "user_id": 4365606,
                "user_type": "registered",
                "profile_image": "https://i.stack.imgur.com/moxWc.jpg?s=128&g=1",
                "display_name": "Jure",
                "link": "https://stackoverflow.com/users/4365606/jure"
            },
            "is_answered": false,
            "view_count": 11,
            "answer_count": 1,
            "score": 0,
            "last_activity_date": 1524658218,
            "creation_date": 1523533376,
            "last_edit_date": 1523535660,
            "question_id": 49795652,
            "body_markdown": "I&#39;m new to portlets and I have a problem with the HelloWorld application. The app displays all the static content (from the index.jsp) but the code inside HelloWorldPortlet.java is not displayed at all. \r\nI&#39;m talking about\r\n\r\n    response.getWriter().print(&quot;Hello World Portlet!&quot;);\r\n\r\nI also put some console log&#39;s (System.out.println) inside the lifecycle methods just to check it out, but nothing is displayed in the console :(\r\n\r\n    public class HelloWorldPortlet extends GenericPortlet{\r\n        public void doView( RenderRequest request, RenderResponse response )\r\n                throws PortletException, IOException {\r\n    System.out.println(&quot;doView()&quot;);\r\n                response.getWriter().print(&quot;Hello World Portlet!&quot;);\r\n            }\r\n    }\r\n\r\nMy guess is that some setting regarding the .java file/class is wrong inside one the numerous XML config files...\r\n\r\nEdit: I&#39;m using the Maven build tool which I only vaguely understand.\r\n\r\npom.xml\r\n\r\n    &lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;\r\n    \txsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/maven-v4_0_0.xsd&quot;&gt;\r\n    \t&lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;\r\n    \t&lt;groupId&gt;com.journaldev&lt;/groupId&gt;\r\n    \t&lt;artifactId&gt;HelloWorldPortlet&lt;/artifactId&gt;\r\n    \t&lt;packaging&gt;war&lt;/packaging&gt;\r\n    \t&lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt;\r\n    \t&lt;name&gt;HelloWorldPortlet Maven Webapp&lt;/name&gt;\r\n    \t&lt;url&gt;http://maven.apache.org&lt;/url&gt;\r\n    \t&lt;dependencies&gt;\r\n    \t\t&lt;dependency&gt;\r\n    \t\t\t&lt;groupId&gt;org.apache.portals&lt;/groupId&gt;\r\n    \t\t\t&lt;artifactId&gt;portlet-api_2.0_spec&lt;/artifactId&gt;\r\n    \t\t\t&lt;version&gt;1.0&lt;/version&gt;\r\n    \t\t\t&lt;scope&gt;provided&lt;/scope&gt;\r\n    \t\t&lt;/dependency&gt;\r\n    \t&lt;/dependencies&gt;\r\n    \t&lt;build&gt;\r\n    \t\t&lt;plugins&gt;\r\n    \t\t\t&lt;plugin&gt;\r\n    \t\t\t\t&lt;groupId&gt;org.apache.portals.pluto&lt;/groupId&gt;\r\n    \t\t\t\t&lt;artifactId&gt;maven-pluto-plugin&lt;/artifactId&gt;\r\n    \t\t\t\t&lt;version&gt;2.1.0-M3&lt;/version&gt;\r\n    \t\t\t\t&lt;executions&gt;\r\n    \t\t\t\t\t&lt;execution&gt;\r\n    \t\t\t\t\t\t&lt;phase&gt;generate-resources&lt;/phase&gt;\r\n    \t\t\t\t\t\t&lt;goals&gt;\r\n    \t\t\t\t\t\t\t&lt;goal&gt;assemble&lt;/goal&gt;\r\n    \t\t\t\t\t\t&lt;/goals&gt;\r\n    \t\t\t\t\t&lt;/execution&gt;\r\n    \t\t\t\t&lt;/executions&gt;\r\n    \t\t\t&lt;/plugin&gt;\r\n    \t\t\t&lt;plugin&gt;\r\n    \t\t\t\t&lt;artifactId&gt;maven-war-plugin&lt;/artifactId&gt;\r\n    \t\t\t\t&lt;configuration&gt;\r\n    \t\t\t\t\t&lt;webXml&gt;${project.build.directory}/pluto-resources/web.xml&lt;/webXml&gt;\r\n    \t\t\t\t&lt;/configuration&gt;\r\n    \t\t\t&lt;/plugin&gt;\r\n    \t\t&lt;/plugins&gt;\r\n    \t\t&lt;finalName&gt;HelloWorldPortlet&lt;/finalName&gt;\r\n    \t&lt;/build&gt;\r\n    &lt;/project&gt;",
            "link": "https://stackoverflow.com/questions/49795652/apache-pluto-portlet-set-path-to-java-file",
            "title": "Apache Pluto portlet set path to .java file",
            "body": "<p>I'm new to portlets and I have a problem with the HelloWorld application. The app displays all the static content (from the index.jsp) but the code inside HelloWorldPortlet.java is not displayed at all. \nI'm talking about</p>\n\n<pre><code>response.getWriter().print(\"Hello World Portlet!\");\n</code></pre>\n\n<p>I also put some console log's (System.out.println) inside the lifecycle methods just to check it out, but nothing is displayed in the console :(</p>\n\n<pre><code>public class HelloWorldPortlet extends GenericPortlet{\n    public void doView( RenderRequest request, RenderResponse response )\n            throws PortletException, IOException {\nSystem.out.println(\"doView()\");\n            response.getWriter().print(\"Hello World Portlet!\");\n        }\n}\n</code></pre>\n\n<p>My guess is that some setting regarding the .java file/class is wrong inside one the numerous XML config files...</p>\n\n<p>Edit: I'm using the Maven build tool which I only vaguely understand.</p>\n\n<p>pom.xml</p>\n\n<pre><code>&lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n    xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/maven-v4_0_0.xsd\"&gt;\n    &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;\n    &lt;groupId&gt;com.journaldev&lt;/groupId&gt;\n    &lt;artifactId&gt;HelloWorldPortlet&lt;/artifactId&gt;\n    &lt;packaging&gt;war&lt;/packaging&gt;\n    &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt;\n    &lt;name&gt;HelloWorldPortlet Maven Webapp&lt;/name&gt;\n    &lt;url&gt;http://maven.apache.org&lt;/url&gt;\n    &lt;dependencies&gt;\n        &lt;dependency&gt;\n            &lt;groupId&gt;org.apache.portals&lt;/groupId&gt;\n            &lt;artifactId&gt;portlet-api_2.0_spec&lt;/artifactId&gt;\n            &lt;version&gt;1.0&lt;/version&gt;\n            &lt;scope&gt;provided&lt;/scope&gt;\n        &lt;/dependency&gt;\n    &lt;/dependencies&gt;\n    &lt;build&gt;\n        &lt;plugins&gt;\n            &lt;plugin&gt;\n                &lt;groupId&gt;org.apache.portals.pluto&lt;/groupId&gt;\n                &lt;artifactId&gt;maven-pluto-plugin&lt;/artifactId&gt;\n                &lt;version&gt;2.1.0-M3&lt;/version&gt;\n                &lt;executions&gt;\n                    &lt;execution&gt;\n                        &lt;phase&gt;generate-resources&lt;/phase&gt;\n                        &lt;goals&gt;\n                            &lt;goal&gt;assemble&lt;/goal&gt;\n                        &lt;/goals&gt;\n                    &lt;/execution&gt;\n                &lt;/executions&gt;\n            &lt;/plugin&gt;\n            &lt;plugin&gt;\n                &lt;artifactId&gt;maven-war-plugin&lt;/artifactId&gt;\n                &lt;configuration&gt;\n                    &lt;webXml&gt;${project.build.directory}/pluto-resources/web.xml&lt;/webXml&gt;\n                &lt;/configuration&gt;\n            &lt;/plugin&gt;\n        &lt;/plugins&gt;\n        &lt;finalName&gt;HelloWorldPortlet&lt;/finalName&gt;\n    &lt;/build&gt;\n&lt;/project&gt;\n</code></pre>\n"
        },
        {
            "tags": [
                "android",
                "android-textview",
                "visibility"
            ],
            "owner": {
                "reputation": 1,
                "user_id": 7342216,
                "user_type": "registered",
                "accept_rate": 0,
                "profile_image": "https://www.gravatar.com/avatar/87bcafbcb8c61780539086435a313e1b?s=128&d=identicon&r=PG&f=1",
                "display_name": "Priyanka G",
                "link": "https://stackoverflow.com/users/7342216/priyanka-g"
            },
            "is_answered": false,
            "view_count": 32,
            "answer_count": 2,
            "score": 0,
            "last_activity_date": 1524658217,
            "creation_date": 1524655758,
            "question_id": 50021164,
            "body_markdown": "I have two fragments A and B. In my &#39;A&#39; fragment, there is Textview variable and which is public static. I want to access fragment &#39;A&#39; Textview variable and change its visibility in fragment &#39;B&#39;. Can anyone help me to solve this problem?  Or anyone could tell me how to pass Textview from Fragment &#39;A&#39; to Fragment &#39;B&#39;.",
            "link": "https://stackoverflow.com/questions/50021164/how-to-change-visibility-of-static-textview-variable-from-another-fragment",
            "title": "How to change visibility of static Textview variable from another fragment?",
            "body": "<p>I have two fragments A and B. In my 'A' fragment, there is Textview variable and which is public static. I want to access fragment 'A' Textview variable and change its visibility in fragment 'B'. Can anyone help me to solve this problem?  Or anyone could tell me how to pass Textview from Fragment 'A' to Fragment 'B'.</p>\n"
        },
        {
            "tags": [
                "ssl",
                "iis",
                "certificate",
                "export"
            ],
            "owner": {
                "reputation": 25,
                "user_id": 3805070,
                "user_type": "registered",
                "profile_image": "https://i.stack.imgur.com/hv55D.png?s=128&g=1",
                "display_name": "Yelhigh",
                "link": "https://stackoverflow.com/users/3805070/yelhigh"
            },
            "is_answered": false,
            "view_count": 11,
            "answer_count": 0,
            "score": 0,
            "last_activity_date": 1524658216,
            "creation_date": 1524658216,
            "question_id": 50021993,
            "body_markdown": "problem is simple. Some time ago I just exported the SSL certificate from IIS. Now it&#39;s impossible. Did anyone have issue like this?\r\n\r\nExporting certificate with open and &quot;copy to file&quot; ends with making the .cer file instead of .pfx, which is needed.\r\n\r\n[![No export position here.][1]][1]\r\n\r\n\r\n  [1]: https://i.stack.imgur.com/GSXzg.png",
            "link": "https://stackoverflow.com/questions/50021993/ssl-certificate-export-no-position-in-menu",
            "title": "SSL certificate export - no position in menu",
            "body": "<p>problem is simple. Some time ago I just exported the SSL certificate from IIS. Now it's impossible. Did anyone have issue like this?</p>\n\n<p>Exporting certificate with open and \"copy to file\" ends with making the .cer file instead of .pfx, which is needed.</p>\n\n<p><a href=\"https://i.stack.imgur.com/GSXzg.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/GSXzg.png\" alt=\"No export position here.\"></a></p>\n"
        },
        {
            "tags": [
                "json",
                "kotlin",
                "klaxon"
            ],
            "owner": {
                "reputation": 168,
                "user_id": 2892437,
                "user_type": "registered",
                "accept_rate": 62,
                "profile_image": "https://www.gravatar.com/avatar/c4bd5bf0e1855a6ace4b122842b39003?s=128&d=identicon&r=PG&f=1",
                "display_name": "user2892437",
                "link": "https://stackoverflow.com/users/2892437/user2892437"
            },
            "is_answered": false,
            "view_count": 12,
            "answer_count": 0,
            "score": 0,
            "last_activity_date": 1524658215,
            "creation_date": 1524658160,
            "last_edit_date": 1524658215,
            "question_id": 50021974,
            "body_markdown": "`Gson` allows you set `ExclusionStrategy`&#39;s on a `GsonBuilder` to dynamically skip some fields during serialization.  I&#39;m wondering if the Klaxon library for Kotlin has a similar feature (see https://github.com/cbeust/klaxon). \r\n\r\nThere&#39;s the `Ignore` property annotation that can be set to true or false.  Dynamically setting this to true/false seems clunky but I haven&#39;t found a good approach yet. ",
            "link": "https://stackoverflow.com/questions/50021974/json-serialization-exclusion-strategy-with-klaxon",
            "title": "JSON serialization exclusion strategy with Klaxon",
            "body": "<p><code>Gson</code> allows you set <code>ExclusionStrategy</code>'s on a <code>GsonBuilder</code> to dynamically skip some fields during serialization.  I'm wondering if the Klaxon library for Kotlin has a similar feature (see <a href=\"https://github.com/cbeust/klaxon\" rel=\"nofollow noreferrer\">https://github.com/cbeust/klaxon</a>). </p>\n\n<p>There's the <code>Ignore</code> property annotation that can be set to true or false.  Dynamically setting this to true/false seems clunky but I haven't found a good approach yet. </p>\n"
        },
        {
            "tags": [
                "sql",
                "sql-server"
            ],
            "owner": {
                "reputation": 21,
                "user_id": 9574893,
                "user_type": "registered",
                "profile_image": "https://www.gravatar.com/avatar/2ea77455f7e48bdf52c25b64f67e45e9?s=128&d=identicon&r=PG&f=1",
                "display_name": "Bharath",
                "link": "https://stackoverflow.com/users/9574893/bharath"
            },
            "is_answered": true,
            "view_count": 48,
            "accepted_answer_id": 50021321,
            "answer_count": 5,
            "score": 1,
            "last_activity_date": 1524658214,
            "creation_date": 1524655468,
            "last_edit_date": 1524656889,
            "question_id": 50021066,
            "body_markdown": "   \r\nSo if I have a data (varchar) like say `10.1`\r\n\r\nI need the value as `0000101000000`.\r\n\r\nmeans (000010) whole number and (1000000) decimal value.   \r\n\r\nIts a 13 character string ,numbers coming before decimal point should be in first 6 characters and numbers coming after decimal point should be in last 7 characters       ",
            "link": "https://stackoverflow.com/questions/50021066/need-to-pad-zeros-left-and-right-for-a-string-value-according-to-decimal-format",
            "title": "Need to pad zeros left and right for a string value according to decimal format",
            "body": "<p>So if I have a data (varchar) like say <code>10.1</code></p>\n\n<p>I need the value as <code>0000101000000</code>.</p>\n\n<p>means (000010) whole number and (1000000) decimal value.   </p>\n\n<p>Its a 13 character string ,numbers coming before decimal point should be in first 6 characters and numbers coming after decimal point should be in last 7 characters       </p>\n"
        },
        {
            "tags": [
                "encryption",
                "rsa"
            ],
            "owner": {
                "reputation": 462,
                "user_id": 383269,
                "user_type": "registered",
                "accept_rate": 51,
                "profile_image": "https://www.gravatar.com/avatar/5526bf57d5775d0233f70dcb93b2bb2b?s=128&d=identicon&r=PG",
                "display_name": "lebron2323",
                "link": "https://stackoverflow.com/users/383269/lebron2323"
            },
            "is_answered": true,
            "view_count": 10870,
            "accepted_answer_id": 11823119,
            "answer_count": 1,
            "score": 7,
            "last_activity_date": 1524658206,
            "creation_date": 1344227733,
            "last_edit_date": 1524658206,
            "question_id": 11822607,
            "body_markdown": "What RSA max block size which I can encrypt in one cycle? \r\n\r\nAnd what is the maximum speed of the RSA algorithm with a 4096 bit key size?",
            "link": "https://stackoverflow.com/questions/11822607/what-is-the-rsa-max-block-size-to-encode",
            "title": "What is the RSA max block size to encode?",
            "body": "<p>What RSA max block size which I can encrypt in one cycle? </p>\n\n<p>And what is the maximum speed of the RSA algorithm with a 4096 bit key size?</p>\n"
        },
        {
            "tags": [
                "regex",
                "perl"
            ],
            "owner": {
                "reputation": 18,
                "user_id": 7714090,
                "user_type": "registered",
                "profile_image": "https://lh5.googleusercontent.com/-mgTrEfljBZM/AAAAAAAAAAI/AAAAAAAAACI/aiv61tMmDbE/photo.jpg?sz=128",
                "display_name": "Bhavik Shah",
                "link": "https://stackoverflow.com/users/7714090/bhavik-shah"
            },
            "is_answered": true,
            "view_count": 32,
            "answer_count": 2,
            "score": 1,
            "last_activity_date": 1524658205,
            "creation_date": 1524642471,
            "last_edit_date": 1524651824,
            "question_id": 50016733,
            "body_markdown": "Since &#39;#&#39; is treated as character for comment in Perl, I would like to diff out sentence where the it starts with hash(pound) sign. I am trying to make incremental backup of a device but the line which has hash in it, keeps on changing the modified time of the device.\r\n\r\n     ! # Last modified Wed Apr 25 12:57:50 2018\r\n       set ns config -IPAddress x.x.x.x -netmask 255.255.255.0\r\n       enable ns feature WL LB CS SSL CF SSLVPN REWRITE RESPONDER\r\n       enable ns mode FR L3 MBF Edge USNIP PMTUD\r\n     --- 1,6 ----\r\n       show run\r\n       #NS12.0 Build 53.22\r\n     ! # Last modified Wed Apr 25 13:02:05 2018\r\n       set ns config -IPAddress x.x.x.x -netmask 255.255.255.0\r\n       enable ns feature WL LB CS SSL CF SSLVPN REWRITE RESPONDER\r\n       enable ns mode FR L3 MBF Edge USNIP PMTUD\r\n\r\nSo far in the script, I am using below string to match but its not working.\r\n\r\n    if(open(F, &quot;+&lt; $incoming&quot;)) {\r\n        my $out = &#39;&#39;;\r\n        while (&lt;F&gt;) {\r\n           /\\#\\ Last modified&quot;/ and next;\r\n          $out .= $_;\r\n        }\r\n\r\nAny leads on how to remove entire sentence who has &quot;# Last modified&quot; ?\r\n",
            "link": "https://stackoverflow.com/questions/50016733/skip-lines-in-file-that-match-a-string",
            "title": "Skip lines in file that match a string",
            "body": "<p>Since '#' is treated as character for comment in Perl, I would like to diff out sentence where the it starts with hash(pound) sign. I am trying to make incremental backup of a device but the line which has hash in it, keeps on changing the modified time of the device.</p>\n\n<pre><code> ! # Last modified Wed Apr 25 12:57:50 2018\n   set ns config -IPAddress x.x.x.x -netmask 255.255.255.0\n   enable ns feature WL LB CS SSL CF SSLVPN REWRITE RESPONDER\n   enable ns mode FR L3 MBF Edge USNIP PMTUD\n --- 1,6 ----\n   show run\n   #NS12.0 Build 53.22\n ! # Last modified Wed Apr 25 13:02:05 2018\n   set ns config -IPAddress x.x.x.x -netmask 255.255.255.0\n   enable ns feature WL LB CS SSL CF SSLVPN REWRITE RESPONDER\n   enable ns mode FR L3 MBF Edge USNIP PMTUD\n</code></pre>\n\n<p>So far in the script, I am using below string to match but its not working.</p>\n\n<pre><code>if(open(F, \"+&lt; $incoming\")) {\n    my $out = '';\n    while (&lt;F&gt;) {\n       /\\#\\ Last modified\"/ and next;\n      $out .= $_;\n    }\n</code></pre>\n\n<p>Any leads on how to remove entire sentence who has \"# Last modified\" ?</p>\n"
        },
        {
            "tags": [
                "javascript",
                "java",
                "angularjs",
                "pojo"
            ],
            "owner": {
                "reputation": 15,
                "user_id": 9066659,
                "user_type": "registered",
                "accept_rate": 0,
                "profile_image": "https://www.gravatar.com/avatar/43a8624d9a7ec0d93493c0662e7debd7?s=128&d=identicon&r=PG&f=1",
                "display_name": "Mark",
                "link": "https://stackoverflow.com/users/9066659/mark"
            },
            "is_answered": true,
            "view_count": 72,
            "answer_count": 1,
            "score": 0,
            "last_activity_date": 1524658205,
            "creation_date": 1524654412,
            "last_edit_date": 1524658205,
            "question_id": 50020723,
            "body_markdown": "Before saving\r\n[![enter image description here][1]][1]\r\n\r\nAfter saving\r\n[![enter image description here][2]][2]\r\n \r\n\r\n    @Entity\r\n    @JsonIgnoreProperties({&quot;hibernateLazyInitializer&quot;, &quot;handler&quot;})\r\n    public class Notification {\r\n     \r\n    \r\n      @Id\r\n        @GeneratedValue(strategy = GenerationType.AUTO)\r\n        private Long notificationId;\r\n        private Long businessId;\r\n        private String actionBy;\r\n        private String date;\r\n        private String notification;\r\n        public ArrayList&lt;UserNotification&gt; user;\r\n    \r\n      //constructor here\r\n    \r\n      //getters setters here\r\n    }\r\n\r\nand UserNotification.java is\r\n\r\n    public class UserNotification {\r\n    private Long id;\r\n    private String user;\r\n    private String notifCount;\r\n    //getters setters here\r\n    }\r\n\r\n\r\nI don&#39;t know why is it returning null. At what point I made a mistake?\r\n\r\nEDIT:\r\n\r\n     var usersObj=[];\r\n            BusinessRoleService.getByBusinessId($sessionStorage.businessRole.business).then(function(response){\r\n                if(response.status==200){\r\n                    for(var x=0;x&lt;response.data.length;x++){\r\n                        usersObj.push({id: x, user: response.data[x].userId, notifCount: $scope.notification});\r\n                    }\r\n    \r\n    \r\n                }\r\n            });\r\n    \r\n            var obj = {\r\n                &quot;businessId&quot;: businessId,\r\n                &quot;actionBy&quot;: user,\r\n                &quot;date&quot;: date,\r\n                &quot;notification&quot;: user+&quot; &quot;+action,\r\n                &quot;user&quot;: usersObj\r\n            }\r\n\r\n\r\nthen I will pass the obj to my service to save\r\n\r\nThis is what my database looks like after saving\r\n\r\n[![enter image description here][3]][3]\r\n\r\n\r\n  [1]: https://i.stack.imgur.com/hjpXa.jpg\r\n  [2]: https://i.stack.imgur.com/xABzN.jpg\r\n  [3]: https://i.stack.imgur.com/c1Hzk.jpg",
            "link": "https://stackoverflow.com/questions/50020723/how-to-save-a-list-in-an-object-using-java",
            "title": "How to save a list in an object using Java?",
            "body": "<p>Before saving\n<a href=\"https://i.stack.imgur.com/hjpXa.jpg\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/hjpXa.jpg\" alt=\"enter image description here\"></a></p>\n\n<p>After saving\n<a href=\"https://i.stack.imgur.com/xABzN.jpg\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/xABzN.jpg\" alt=\"enter image description here\"></a></p>\n\n<pre><code>@Entity\n@JsonIgnoreProperties({\"hibernateLazyInitializer\", \"handler\"})\npublic class Notification {\n\n\n  @Id\n    @GeneratedValue(strategy = GenerationType.AUTO)\n    private Long notificationId;\n    private Long businessId;\n    private String actionBy;\n    private String date;\n    private String notification;\n    public ArrayList&lt;UserNotification&gt; user;\n\n  //constructor here\n\n  //getters setters here\n}\n</code></pre>\n\n<p>and UserNotification.java is</p>\n\n<pre><code>public class UserNotification {\nprivate Long id;\nprivate String user;\nprivate String notifCount;\n//getters setters here\n}\n</code></pre>\n\n<p>I don't know why is it returning null. At what point I made a mistake?</p>\n\n<p>EDIT:</p>\n\n<pre><code> var usersObj=[];\n        BusinessRoleService.getByBusinessId($sessionStorage.businessRole.business).then(function(response){\n            if(response.status==200){\n                for(var x=0;x&lt;response.data.length;x++){\n                    usersObj.push({id: x, user: response.data[x].userId, notifCount: $scope.notification});\n                }\n\n\n            }\n        });\n\n        var obj = {\n            \"businessId\": businessId,\n            \"actionBy\": user,\n            \"date\": date,\n            \"notification\": user+\" \"+action,\n            \"user\": usersObj\n        }\n</code></pre>\n\n<p>then I will pass the obj to my service to save</p>\n\n<p>This is what my database looks like after saving</p>\n\n<p><a href=\"https://i.stack.imgur.com/c1Hzk.jpg\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/c1Hzk.jpg\" alt=\"enter image description here\"></a></p>\n"
        },
        {
            "tags": [
                "python",
                "django",
                "pandas",
                "numpy"
            ],
            "owner": {
                "reputation": 9,
                "user_id": 6324046,
                "user_type": "registered",
                "accept_rate": 40,
                "profile_image": "https://www.gravatar.com/avatar/81d1612020eadf394c626d29f6eef9a0?s=128&d=identicon&r=PG&f=1",
                "display_name": "TJA",
                "link": "https://stackoverflow.com/users/6324046/tja"
            },
            "is_answered": false,
            "view_count": 170,
            "answer_count": 1,
            "score": 0,
            "last_activity_date": 1524658204,
            "creation_date": 1486910546,
            "last_edit_date": 1486910778,
            "question_id": 42188940,
            "body_markdown": "may I check why am I unable to import numpy or pandas into django? it keeps giving \r\n\r\n    import numpy as np\r\n    ImportError: No module named numpy\r\n\r\nThe below is my code to import it. I&#39;m importing at the views.py btw\r\n\r\n    from django.shortcuts import render\r\n    from django.template import loader\r\n    from django.http import HttpResponse\r\n    import numpy as np\r\n\r\n\r\n",
            "link": "https://stackoverflow.com/questions/42188940/unable-to-import-numpy-and-pandas-into-django",
            "title": "unable to import numpy and pandas into django",
            "body": "<p>may I check why am I unable to import numpy or pandas into django? it keeps giving </p>\n\n<pre><code>import numpy as np\nImportError: No module named numpy\n</code></pre>\n\n<p>The below is my code to import it. I'm importing at the views.py btw</p>\n\n<pre><code>from django.shortcuts import render\nfrom django.template import loader\nfrom django.http import HttpResponse\nimport numpy as np\n</code></pre>\n"
        },
        {
            "tags": [
                "react-native"
            ],
            "owner": {
                "reputation": 172,
                "user_id": 5775871,
                "user_type": "registered",
                "accept_rate": 53,
                "profile_image": "https://www.gravatar.com/avatar/660bbb27aea7e8bfd87a0d526876e705?s=128&d=identicon&r=PG&f=1",
                "display_name": "Shashika",
                "link": "https://stackoverflow.com/users/5775871/shashika"
            },
            "is_answered": true,
            "view_count": 20,
            "accepted_answer_id": 50021988,
            "answer_count": 1,
            "score": 0,
            "last_activity_date": 1524658202,
            "creation_date": 1524656564,
            "last_edit_date": 1524657931,
            "question_id": 50021438,
            "body_markdown": "In my project, I used stack navigator as the navigator. Inside navigationOptions, at headerRight, I used a custom button. When I try to call the onPress, it says the function is not a function.\r\n\r\nthis is the function\r\n\r\n      sharePost() {\r\n        // this.props.doShare();\r\n        console.log(&quot;DONE&quot;);\r\n      }\r\n\r\nI have put the full code here. I want to use sharePost function inside the rightHeader of navigationOptions. \r\n\r\n         import React, { Component } from &quot;react&quot;;\r\n    import Icon from &quot;react-native-vector-icons/MaterialCommunityIcons&quot;;\r\n    import {\r\n      View,\r\n      Text,\r\n      Image,\r\n      TouchableOpacity,\r\n      Animated,\r\n      ScrollView,\r\n      StyleSheet,\r\n      Dimensions\r\n    } from &quot;react-native&quot;;\r\n    \r\n    import { PostProfileBar, WritePost } from &quot;../../components&quot;;\r\n    import { ButtonWithoutBackground } from &quot;../../mixing/UI&quot;;\r\n    \r\n    const width = Dimensions.get(&quot;window&quot;).width;\r\n    const height = Dimensions.get(&quot;window&quot;).height / 3;\r\n    \r\n    class SharePostScreen extends Component {\r\n      constructor(props) {\r\n        super(props);\r\n    \r\n      sharePost() {\r\n        // this.props.doShare();\r\n        console.log(&quot;DONE&quot;);\r\n      }\r\n    \r\n      render() {\r\n        return (\r\n          &lt;View style={styles.container}&gt;\r\n            &lt;ScrollView&gt;\r\n              &lt;WritePost profile={this.state.loggedUserProfile} /&gt;\r\n    \r\n              &lt;View style={styles.sharePostWrapper}&gt;\r\n                &lt;PostProfileBar profile={this.state.postedUserProfile} /&gt;\r\n    \r\n                &lt;Image\r\n                  source={{\r\n                    uri: &quot;https://pbs.twimg.com/media/DWvRLbBVoAA4CCM.jpg&quot;\r\n                  }}\r\n                  resizeMode={&quot;stretch&quot;}\r\n                  style={styles.image}\r\n                /&gt;\r\n              &lt;/View&gt;\r\n            &lt;/ScrollView&gt;\r\n          &lt;/View&gt;\r\n        );\r\n      }\r\n    \r\n      static navigationOptions = ({ navigation }) =&gt; ({\r\n        headerTitle: &quot;Share To Feed&quot;,\r\n        headerTitleStyle: {\r\n          paddingLeft: &quot;20%&quot;,\r\n          paddingRight: &quot;20%&quot;\r\n        },\r\n        headerStyle: {\r\n          paddingRight: 10,\r\n          paddingLeft: 10\r\n        },\r\n        headerLeft: (\r\n          &lt;Icon\r\n            name={&quot;close&quot;}\r\n            size={30}\r\n            onPress={() =&gt; {\r\n              navigation.goBack();\r\n            }}\r\n          /&gt;\r\n        ),\r\n        headerRight: (\r\n          &lt;ButtonWithoutBackground\r\n            buttonText={styles.buttonText}\r\n            onPress={this.sharePost()}\r\n          &gt;\r\n            Post\r\n          &lt;/ButtonWithoutBackground&gt;\r\n        )\r\n      });\r\n    }\r\n\r\n",
            "link": "https://stackoverflow.com/questions/50021438/function-is-not-a-function-react-native",
            "title": "function is not a function - react-native",
            "body": "<p>In my project, I used stack navigator as the navigator. Inside navigationOptions, at headerRight, I used a custom button. When I try to call the onPress, it says the function is not a function.</p>\n\n<p>this is the function</p>\n\n<pre><code>  sharePost() {\n    // this.props.doShare();\n    console.log(\"DONE\");\n  }\n</code></pre>\n\n<p>I have put the full code here. I want to use sharePost function inside the rightHeader of navigationOptions. </p>\n\n<pre><code>     import React, { Component } from \"react\";\nimport Icon from \"react-native-vector-icons/MaterialCommunityIcons\";\nimport {\n  View,\n  Text,\n  Image,\n  TouchableOpacity,\n  Animated,\n  ScrollView,\n  StyleSheet,\n  Dimensions\n} from \"react-native\";\n\nimport { PostProfileBar, WritePost } from \"../../components\";\nimport { ButtonWithoutBackground } from \"../../mixing/UI\";\n\nconst width = Dimensions.get(\"window\").width;\nconst height = Dimensions.get(\"window\").height / 3;\n\nclass SharePostScreen extends Component {\n  constructor(props) {\n    super(props);\n\n  sharePost() {\n    // this.props.doShare();\n    console.log(\"DONE\");\n  }\n\n  render() {\n    return (\n      &lt;View style={styles.container}&gt;\n        &lt;ScrollView&gt;\n          &lt;WritePost profile={this.state.loggedUserProfile} /&gt;\n\n          &lt;View style={styles.sharePostWrapper}&gt;\n            &lt;PostProfileBar profile={this.state.postedUserProfile} /&gt;\n\n            &lt;Image\n              source={{\n                uri: \"https://pbs.twimg.com/media/DWvRLbBVoAA4CCM.jpg\"\n              }}\n              resizeMode={\"stretch\"}\n              style={styles.image}\n            /&gt;\n          &lt;/View&gt;\n        &lt;/ScrollView&gt;\n      &lt;/View&gt;\n    );\n  }\n\n  static navigationOptions = ({ navigation }) =&gt; ({\n    headerTitle: \"Share To Feed\",\n    headerTitleStyle: {\n      paddingLeft: \"20%\",\n      paddingRight: \"20%\"\n    },\n    headerStyle: {\n      paddingRight: 10,\n      paddingLeft: 10\n    },\n    headerLeft: (\n      &lt;Icon\n        name={\"close\"}\n        size={30}\n        onPress={() =&gt; {\n          navigation.goBack();\n        }}\n      /&gt;\n    ),\n    headerRight: (\n      &lt;ButtonWithoutBackground\n        buttonText={styles.buttonText}\n        onPress={this.sharePost()}\n      &gt;\n        Post\n      &lt;/ButtonWithoutBackground&gt;\n    )\n  });\n}\n</code></pre>\n"
        },
        {
            "tags": [
                "javascript",
                "cypress"
            ],
            "owner": {
                "reputation": 102,
                "user_id": 5952758,
                "user_type": "registered",
                "profile_image": "https://www.gravatar.com/avatar/66a752cea1e2c395d0a3372f0208a7cf?s=128&d=identicon&r=PG",
                "display_name": "Tarek",
                "link": "https://stackoverflow.com/users/5952758/tarek"
            },
            "is_answered": false,
            "view_count": 33,
            "answer_count": 0,
            "score": 0,
            "last_activity_date": 1524658197,
            "creation_date": 1524645120,
            "last_edit_date": 1524658197,
            "question_id": 50017524,
            "body_markdown": "I want to store some data from a specific web site to a Json or a text file, i&#39;m using Cypress and i already tried selenium and other testing framework for web applications it didn&#39;t work. \r\n\r\nMy console.log print this message (and i need to save the ReadSubscriptionDetailRes array): \r\n\r\n[![enter image description here][1]][1]\r\n\r\n\r\n\r\n\r\n\r\n\r\nAnd a sample source code: \r\n\r\n  \r\n\r\n      describe(&quot;my first test&quot;, function() {\r\n          it(&quot;opens the webpage&quot;, function() {\r\n            cy.server();\r\n            cy.route(&quot;POST&quot;, &quot;/json/**&quot;).as(&quot;getData&quot;);\r\n            cy.wait(100);\r\n            cy.visit(&quot;www.example.com&quot;);\r\n            cy.wait(100);\r\n            cy.wait(&quot;@getData&quot;).then(function(xhr) {\r\n            console.log(xhr.response.body); \r\n            cy.writeFile(&#39;file.json&#39; , xhr.response.body) \r\n            });\r\n          });\r\n        });\r\n\r\n\r\nAnd the content of my file.json is this :\r\n\r\n\r\n&gt; {   &quot;WebEntry&quot;: {\r\n&gt;     &quot;EntryServer&quot;: {\r\n&gt;       &quot;hasBanner&quot;: false,\r\n&gt;       &quot;name&quot;: &quot;xxx&quot;,\r\n&gt;       &quot;path&quot;: &quot;/xxxx&quot;,\r\n&gt;       &quot;version&quot;: &quot;1.0&quot;\r\n&gt;     }   } }\r\n\r\n\r\n  [1]: https://i.stack.imgur.com/j6bX9.png",
            "link": "https://stackoverflow.com/questions/50017524/save-xhr-response-object-to-a-file-cypress",
            "title": "Save XHR response object to a file (Cypress)",
            "body": "<p>I want to store some data from a specific web site to a Json or a text file, i'm using Cypress and i already tried selenium and other testing framework for web applications it didn't work. </p>\n\n<p>My console.log print this message (and i need to save the ReadSubscriptionDetailRes array): </p>\n\n<p><a href=\"https://i.stack.imgur.com/j6bX9.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/j6bX9.png\" alt=\"enter image description here\"></a></p>\n\n<p>And a sample source code: </p>\n\n<pre><code>  describe(\"my first test\", function() {\n      it(\"opens the webpage\", function() {\n        cy.server();\n        cy.route(\"POST\", \"/json/**\").as(\"getData\");\n        cy.wait(100);\n        cy.visit(\"www.example.com\");\n        cy.wait(100);\n        cy.wait(\"@getData\").then(function(xhr) {\n        console.log(xhr.response.body); \n        cy.writeFile('file.json' , xhr.response.body) \n        });\n      });\n    });\n</code></pre>\n\n<p>And the content of my file.json is this :</p>\n\n<blockquote>\n  <p>{   \"WebEntry\": {\n      \"EntryServer\": {\n        \"hasBanner\": false,\n        \"name\": \"xxx\",\n        \"path\": \"/xxxx\",\n        \"version\": \"1.0\"\n      }   } }</p>\n</blockquote>\n"
        },
        {
            "tags": [
                "c#",
                "asp.net-mvc"
            ],
            "owner": {
                "reputation": 23,
                "user_id": 2800811,
                "user_type": "registered",
                "profile_image": "https://graph.facebook.com/1821064617/picture?type=large",
                "display_name": "William Tarte",
                "link": "https://stackoverflow.com/users/2800811/william-tarte"
            },
            "is_answered": true,
            "view_count": 36,
            "answer_count": 1,
            "score": -1,
            "last_activity_date": 1524658188,
            "creation_date": 1524657942,
            "last_edit_date": 1524658117,
            "question_id": 50021895,
            "body_markdown": "I&#39;m not sure why the following is happening, I apologize for this, I&#39;m guessing, simple question.\r\n\r\nI have the following set in a Global Controller.  I did it this way for a couple reasons, most notably for setting a label on a form.\r\n\r\n    public static string CurrentUsername = &quot;&quot;;\r\n\r\nNow, when I deploy, I am seeing that multiple users are updating the variable and the variable is not user specific, what am I doing wrong here?  I am just trying to store the current user that is using the application.  I tried using session, but I ran into difficulties in certain places.\r\n\r\n ",
            "link": "https://stackoverflow.com/questions/50021895/global-variable-seen-by-multiple-users",
            "title": "Global variable seen by multiple users",
            "body": "<p>I'm not sure why the following is happening, I apologize for this, I'm guessing, simple question.</p>\n\n<p>I have the following set in a Global Controller.  I did it this way for a couple reasons, most notably for setting a label on a form.</p>\n\n<pre><code>public static string CurrentUsername = \"\";\n</code></pre>\n\n<p>Now, when I deploy, I am seeing that multiple users are updating the variable and the variable is not user specific, what am I doing wrong here?  I am just trying to store the current user that is using the application.  I tried using session, but I ran into difficulties in certain places.</p>\n"
        },
        {
            "tags": [
                "python",
                "numpy",
                "scipy",
                "arguments",
                "numerical-methods"
            ],
            "owner": {
                "reputation": 8,
                "user_id": 9696757,
                "user_type": "registered",
                "profile_image": "https://i.stack.imgur.com/55tIh.jpg?s=128&g=1",
                "display_name": "Ice-Nine",
                "link": "https://stackoverflow.com/users/9696757/ice-nine"
            },
            "is_answered": true,
            "view_count": 29,
            "accepted_answer_id": 50020104,
            "answer_count": 1,
            "score": 1,
            "last_activity_date": 1524658187,
            "creation_date": 1524652226,
            "last_edit_date": 1524658187,
            "question_id": 50019969,
            "body_markdown": "in scipy there is a function `quad()`:\r\n\r\n    quad(integrand, 0, 1, args=(a,b))\r\n\r\nI have my own function to take integrals using gauss legendgre quadrature, and when I integrate different functions with parameters im kinda tired of adding them. So the question is: \r\n\r\nis there a way to add an argument `args=(...)` into arguments of my own function? ",
            "link": "https://stackoverflow.com/questions/50019969/how-do-i-add-args-into-arguments-of-my-own-function",
            "title": "How do I add &quot;args=(...)&quot; into arguments of my own function?",
            "body": "<p>in scipy there is a function <code>quad()</code>:</p>\n\n<pre><code>quad(integrand, 0, 1, args=(a,b))\n</code></pre>\n\n<p>I have my own function to take integrals using gauss legendgre quadrature, and when I integrate different functions with parameters im kinda tired of adding them. So the question is: </p>\n\n<p>is there a way to add an argument <code>args=(...)</code> into arguments of my own function? </p>\n"
        },
        {
            "tags": [
                "mongodb",
                "mongodb-query",
                "aggregation-framework"
            ],
            "owner": {
                "reputation": 5883,
                "user_id": 455814,
                "user_type": "registered",
                "accept_rate": 71,
                "profile_image": "https://i.stack.imgur.com/Y9DRG.jpg?s=128&g=1",
                "display_name": "Waqas",
                "link": "https://stackoverflow.com/users/455814/waqas"
            },
            "is_answered": true,
            "view_count": 27,
            "accepted_answer_id": 50014555,
            "answer_count": 1,
            "score": 1,
            "last_activity_date": 1524658162,
            "creation_date": 1524632499,
            "last_edit_date": 1524633767,
            "question_id": 50014343,
            "body_markdown": "In mongo collection I have documents of following structure.\r\n\r\n    {\r\n        &quot;_id&quot; : &quot;Suzuki&quot;,\r\n        &quot;qty&quot; : 10,\r\n        &quot;plates&quot; : [ \r\n            {\r\n                &quot;rego&quot; : &quot;1QX-WA-123&quot;,\r\n                &quot;date&quot; : 1516374000000.0\r\n            }, \r\n            {\r\n                &quot;rego&quot; : &quot;1QX-WA-456&quot;,\r\n                &quot;date&quot; : 1513369800000.0\r\n            }\r\n        ],\r\n        &quot;accounts&quot; : [ \r\n            {\r\n                &quot;_id&quot; : &quot;23kpi9MD4KnTvnaW7&quot;,\r\n                &quot;createdAt&quot; : 1513810712802.0,\r\n                &quot;date&quot; : 1503446400000.0,\r\n                &quot;type&quot; : &quot;Suzuki&quot;,\r\n                &quot;rego&quot; : &quot;1QX-WA-123&quot;,\r\n            }, \r\n            {\r\n                &quot;_id&quot; : &quot;2Wqrd4yofvLmqLm5H&quot;,\r\n                &quot;createdAt&quot; : 1513810712802.0,\r\n                &quot;date&quot; : 1501632000000.0,\r\n                &quot;type&quot; : &quot;Suzuki&quot;,\r\n                &quot;rego&quot; : &quot;1QX-WA-111&quot;,\r\n            }\r\n    \t]\r\n    }\r\n\r\nI am trying to filter objects in `accounts` array so that it contains only those objects whose `rego` exists in `plates` array.\r\n\r\nI tried following query, however, it throws an error: `all operands of $setIntersection must be arrays. One argument if of type object.`\r\n\r\n    db.getCollection(&#39;dummy&#39;).aggregate([{\r\n    \t$project: {\r\n            plates: 1, \r\n            accounts: 1,\r\n            intersect: {\r\n                $setIntersection: [\r\n                    { $arrayElemAt: [ &quot;$plates&quot;, 0 ] },\r\n                    { $arrayElemAt: [ &quot;$accounts&quot;, 4 ] }\r\n                ]\r\n            }\r\n        }\r\n    }])\r\n\r\n\r\nThe expected output I am looking for is:\r\n\r\n    {\r\n        &quot;_id&quot; : &quot;Suzuki&quot;,\r\n        &quot;qty&quot; : 10,\r\n        &quot;plates&quot; : [ \r\n            {\r\n                &quot;rego&quot; : &quot;1QX-WA-123&quot;,\r\n                &quot;date&quot; : 1516374000000.0\r\n            }, \r\n            {\r\n                &quot;rego&quot; : &quot;1QX-WA-456&quot;,\r\n                &quot;date&quot; : 1513369800000.0\r\n            }\r\n        ],\r\n        &quot;accounts&quot; : [ \r\n            {\r\n                &quot;_id&quot; : &quot;23kpi9MD4KnTvnaW7&quot;,\r\n                &quot;createdAt&quot; : 1513810712802.0,\r\n                &quot;date&quot; : 1503446400000.0,\r\n                &quot;type&quot; : &quot;Suzuki&quot;,\r\n                &quot;rego&quot; : &quot;1QX-WA-123&quot;,\r\n            }\r\n    \t]\r\n    }\r\n\r\n",
            "link": "https://stackoverflow.com/questions/50014343/finding-intersection-between-two-object-arrays-based-on-field",
            "title": "Finding intersection between two object arrays based on field",
            "body": "<p>In mongo collection I have documents of following structure.</p>\n\n<pre><code>{\n    \"_id\" : \"Suzuki\",\n    \"qty\" : 10,\n    \"plates\" : [ \n        {\n            \"rego\" : \"1QX-WA-123\",\n            \"date\" : 1516374000000.0\n        }, \n        {\n            \"rego\" : \"1QX-WA-456\",\n            \"date\" : 1513369800000.0\n        }\n    ],\n    \"accounts\" : [ \n        {\n            \"_id\" : \"23kpi9MD4KnTvnaW7\",\n            \"createdAt\" : 1513810712802.0,\n            \"date\" : 1503446400000.0,\n            \"type\" : \"Suzuki\",\n            \"rego\" : \"1QX-WA-123\",\n        }, \n        {\n            \"_id\" : \"2Wqrd4yofvLmqLm5H\",\n            \"createdAt\" : 1513810712802.0,\n            \"date\" : 1501632000000.0,\n            \"type\" : \"Suzuki\",\n            \"rego\" : \"1QX-WA-111\",\n        }\n    ]\n}\n</code></pre>\n\n<p>I am trying to filter objects in <code>accounts</code> array so that it contains only those objects whose <code>rego</code> exists in <code>plates</code> array.</p>\n\n<p>I tried following query, however, it throws an error: <code>all operands of $setIntersection must be arrays. One argument if of type object.</code></p>\n\n<pre><code>db.getCollection('dummy').aggregate([{\n    $project: {\n        plates: 1, \n        accounts: 1,\n        intersect: {\n            $setIntersection: [\n                { $arrayElemAt: [ \"$plates\", 0 ] },\n                { $arrayElemAt: [ \"$accounts\", 4 ] }\n            ]\n        }\n    }\n}])\n</code></pre>\n\n<p>The expected output I am looking for is:</p>\n\n<pre><code>{\n    \"_id\" : \"Suzuki\",\n    \"qty\" : 10,\n    \"plates\" : [ \n        {\n            \"rego\" : \"1QX-WA-123\",\n            \"date\" : 1516374000000.0\n        }, \n        {\n            \"rego\" : \"1QX-WA-456\",\n            \"date\" : 1513369800000.0\n        }\n    ],\n    \"accounts\" : [ \n        {\n            \"_id\" : \"23kpi9MD4KnTvnaW7\",\n            \"createdAt\" : 1513810712802.0,\n            \"date\" : 1503446400000.0,\n            \"type\" : \"Suzuki\",\n            \"rego\" : \"1QX-WA-123\",\n        }\n    ]\n}\n</code></pre>\n"
        },
        {
            "tags": [
                "java",
                "jdbc",
                "jvm",
                "classloader"
            ],
            "owner": {
                "reputation": 6,
                "user_id": 5156545,
                "user_type": "registered",
                "profile_image": "https://www.gravatar.com/avatar/1d67759400620854691e9794ddd7c875?s=128&d=identicon&r=PG&f=1",
                "display_name": "lucare",
                "link": "https://stackoverflow.com/users/5156545/lucare"
            },
            "is_answered": false,
            "view_count": 40,
            "answer_count": 0,
            "score": 0,
            "last_activity_date": 1524658154,
            "creation_date": 1524656798,
            "last_edit_date": 1524658154,
            "question_id": 50021531,
            "body_markdown": "Some books say JDBC damage the Parental delegation model, but i read the source about JDBC not found where the breaking shows.\r\n\r\nit seems like every class is loaded by Application Classloader\r\n\r\n    public static void doingJdbc(){\r\n        try {\r\n\r\n            Connection connection = DriverManager.getConnection(&quot;jdbc:mysql://127.0.0.1:3306/design&quot;, &quot;root&quot;, &quot;fengcs&quot;);\r\n\r\n            String sql = &quot;select * from tb_user&quot;;\r\n\r\n            PreparedStatement preparedStatement = connection.prepareStatement(sql);\r\n\r\n            preparedStatement.executeQuery();\r\n\r\n            ResultSet resultSet = preparedStatement.getResultSet();\r\n\r\n            while (resultSet.next()) {\r\n                int id = resultSet.getInt(1);\r\n                System.out.println(&quot;===================&gt;&quot;+ id);\r\n            }\r\n        } catch (Exception ex) {\r\n            ex.printStackTrace();\r\n        }\r\n    }\r\n\r\nIn DriverManager also not found the breaking, i don&#39;t know where the code shows the breaking.\r\n\r\nplease show me the specific code, Thanks.",
            "link": "https://stackoverflow.com/questions/50021531/why-the-book-says-jdbc-damage-the-parental-delegation-model",
            "title": "Why the book says JDBC damage the Parental delegation model",
            "body": "<p>Some books say JDBC damage the Parental delegation model, but i read the source about JDBC not found where the breaking shows.</p>\n\n<p>it seems like every class is loaded by Application Classloader</p>\n\n<pre><code>public static void doingJdbc(){\n    try {\n\n        Connection connection = DriverManager.getConnection(\"jdbc:mysql://127.0.0.1:3306/design\", \"root\", \"fengcs\");\n\n        String sql = \"select * from tb_user\";\n\n        PreparedStatement preparedStatement = connection.prepareStatement(sql);\n\n        preparedStatement.executeQuery();\n\n        ResultSet resultSet = preparedStatement.getResultSet();\n\n        while (resultSet.next()) {\n            int id = resultSet.getInt(1);\n            System.out.println(\"===================&gt;\"+ id);\n        }\n    } catch (Exception ex) {\n        ex.printStackTrace();\n    }\n}\n</code></pre>\n\n<p>In DriverManager also not found the breaking, i don't know where the code shows the breaking.</p>\n\n<p>please show me the specific code, Thanks.</p>\n"
        },
        {
            "tags": [
                "cordova",
                "ionic-framework",
                "inappbrowser",
                "instamojo"
            ],
            "owner": {
                "reputation": 6,
                "user_id": 9697225,
                "user_type": "registered",
                "profile_image": "https://www.gravatar.com/avatar/f4cb22ee7ff17e30552b9b296d5d9b08?s=128&d=identicon&r=PG&f=1",
                "display_name": "Nithya",
                "link": "https://stackoverflow.com/users/9697225/nithya"
            },
            "is_answered": false,
            "view_count": 8,
            "answer_count": 0,
            "score": 1,
            "last_activity_date": 1524658150,
            "creation_date": 1524658150,
            "question_id": 50021968,
            "body_markdown": "I have developed the ionic project in the version 1.3.3. Now I have upgraded the version to 2.0.0 and also dependencies too upgraded to the higher version. Now I was unable to do payment via cordova inappbrowser plugin in android 4.4 and its show the white blank screen. I can do the payment in android version 5 and above. I found the launch.json attributes like version,configurations,type,request are Grey in color and it looks like those attributes are disabled. I have installed the cordova tools and cordova dev essentials extension.\r\n\r\nAnd my environment details:\r\n\r\nCordova CLI: 6.4.0      \r\nIonic Framework Version: 1.3.3   \r\nIonic CLI Version: 2.0.0     \r\nIonic App Lib Version: 2.0.0     \r\nUbuntu Description: Ubuntu 16.10     \r\nNode Version: v6.0.0     \r\nCordova android version: 6.1.2     \r\nAndroid studio version: 3.1     \r\ncordova-plugin-inappbrowser: 1.7.1 \r\n\r\nWhy I was unable to do the payment in android 4.4 and is the cordova was disabled?",
            "link": "https://stackoverflow.com/questions/50021968/instamojo-light-checkout-url-is-not-loading-in-the-cordova-inappbrowser-for-andr",
            "title": "Instamojo light checkout url is not loading in the cordova inappbrowser for android 4.4",
            "body": "<p>I have developed the ionic project in the version 1.3.3. Now I have upgraded the version to 2.0.0 and also dependencies too upgraded to the higher version. Now I was unable to do payment via cordova inappbrowser plugin in android 4.4 and its show the white blank screen. I can do the payment in android version 5 and above. I found the launch.json attributes like version,configurations,type,request are Grey in color and it looks like those attributes are disabled. I have installed the cordova tools and cordova dev essentials extension.</p>\n\n<p>And my environment details:</p>\n\n<p>Cordova CLI: 6.4.0<br>\nIonic Framework Version: 1.3.3<br>\nIonic CLI Version: 2.0.0<br>\nIonic App Lib Version: 2.0.0<br>\nUbuntu Description: Ubuntu 16.10<br>\nNode Version: v6.0.0<br>\nCordova android version: 6.1.2<br>\nAndroid studio version: 3.1<br>\ncordova-plugin-inappbrowser: 1.7.1 </p>\n\n<p>Why I was unable to do the payment in android 4.4 and is the cordova was disabled?</p>\n"
        },
        {
            "tags": [
                "python",
                "tensorflow",
                "gradient-descent"
            ],
            "owner": {
                "reputation": 12,
                "user_id": 9413255,
                "user_type": "registered",
                "profile_image": "https://www.gravatar.com/avatar/fd9b3eb7b5f06d400fcf29329657981c?s=128&d=identicon&r=PG&f=1",
                "display_name": "D. vd V.",
                "link": "https://stackoverflow.com/users/9413255/d-vd-v"
            },
            "is_answered": false,
            "view_count": 27,
            "answer_count": 0,
            "score": 0,
            "last_activity_date": 1524658148,
            "creation_date": 1524644803,
            "last_edit_date": 1524658148,
            "question_id": 50017432,
            "body_markdown": "I want to implement a Cyclic Learning Rate, as opposed to AdamOptimizer or any other form of SGD for example.\r\nSo the part I want to introduce here is a &quot;Cyclic Learning Rate&quot;, with the function `get_triangular_lr`. The function is shown below: \r\n\r\n    def get_triangular_lr(iteration, stepsize, base_lr, max_lr):\r\n        &quot;&quot;&quot;Given the inputs, calculates the lr that should be applicable for \r\n           this iteration&quot;&quot;&quot;\r\n        scale_fn = lambda x: 1/(2.**(x-1))\r\n        cycle = math.floor(1 + iteration/(2  * stepsize))\r\n        x = abs(iteration/stepsize - 2 * cycle + 1)\r\n        lr = base_lr + (max_lr - base_lr) * max(0, (1-x)) *scale_fn(cycle)\r\n        lr = tf.convert_to_tensor(lr)\r\n\r\n        return lr                \r\n\r\nBelow, the code is shown for using this in the actual Inception ResNet V2 model, my aim is to replace `tf_train_exponential_decay` with the Cyclic LR, which itself increases and decreases learning rate per step taken. \r\n     \r\n          iteration_step = 0 #(is increased every global_step)\r\n          lr1 = get_triangular_lr(iteration_step, stepsize, base_lr, max_lr)\r\n       \r\n\r\n        #Define your exponentially decaying learning rate\r\n    #         lr = tf.train.exponential_decay(\r\n    #             learning_rate = initial_learning_rate,\r\n    #             global_step = global_step,\r\n    #             decay_steps = decay_steps,\r\n    #             decay_rate = learning_rate_decay_factor,\r\n    #             staircase = True)\r\n\r\n        #Now we can define the optimizer that takes on the learning rate\r\n        \r\n        optimizer = tf.train.AdamOptimizer(learning_rate = lr1)\r\n\r\n        #Create the train_op.\r\n        train_op = slim.learning.create_train_op(total_loss, optimizer)\r\n\r\nHowever, when I run the code above (by running the complete training model), the learning rate never gets increased by using that function. It only starts at `0.0001`, and every global_step taken it uses this value, while it should be increasing every global step (with the new value calculated by `get_triangular_lr`. I think it requires some kind of for-loop, but I can&#39;t figure out how exactly to implement it.\r\n       \r\n\r\n\r\n        #Now we need to create a training step function that runs both the \r\n        #train_op, metrics_op and updates the global_step concurrently.\r\n\r\n        def train_step(sess, train_op, global_step):\r\n            &#39;&#39;&#39;\r\n            Simply runs a session for the three arguments provided and gives a \r\n         logging on the time elapsed for each global step\r\n            &#39;&#39;&#39;\r\n            #Check the time for each sess run\r\n            start_time = time.time()\r\n            total_loss, global_step_count, _ = sess.run([train_op, global_step, \r\n            metrics_op])\r\n            time_elapsed = time.time() - start_time\r\n\r\n            #Run the logging to print some results\r\n            logging.info(&#39;global step %s: loss: %.4f (%.2f sec/step)&#39;, \r\n            global_step_count, total_loss, time_elapsed)\r\n\r\n            return total_loss, global_step_count\r\n\r\nWhen I change the input of `train_op` to `total_loss, lr1` it gives me an AttributeError: &#39;Tensor&#39; object has no attribute &#39;compute_gradients&#39;, and thus the model does not run at all. \r\n\r\n\r\n**EDIT: Have not yet found solution yet, but managed to use py.func, but now the next error occurs:**\r\n\r\nSo I created `triangular_tf`, which uses `tf.py_func` to load the function, as follows:\r\n\r\n    triangular_tf = tf.py_func(get_triangular_lr, [iteration, stepsize, base_lr, max_lr], [tf.float64])\r\n\r\nThe only issue is, when I now pass `triangular_tf` to `optimizer = tf.train.AdamOptimizer(learning_rate = triangular_tf) the following error occurs:\r\n\r\n`ValueError: cannot add op with name &lt;my weights variable name&gt;/Adam as that name is already used`\r\n\r\nNot sure whether I still need the AdamOptimizer in this process, but I just simply need a way to adjust learning rate every step.",
            "link": "https://stackoverflow.com/questions/50017432/implement-variable-learning-rate-tensorflow",
            "title": "Implement variable learning rate Tensorflow",
            "body": "<p>I want to implement a Cyclic Learning Rate, as opposed to AdamOptimizer or any other form of SGD for example.\nSo the part I want to introduce here is a \"Cyclic Learning Rate\", with the function <code>get_triangular_lr</code>. The function is shown below: </p>\n\n<pre><code>def get_triangular_lr(iteration, stepsize, base_lr, max_lr):\n    \"\"\"Given the inputs, calculates the lr that should be applicable for \n       this iteration\"\"\"\n    scale_fn = lambda x: 1/(2.**(x-1))\n    cycle = math.floor(1 + iteration/(2  * stepsize))\n    x = abs(iteration/stepsize - 2 * cycle + 1)\n    lr = base_lr + (max_lr - base_lr) * max(0, (1-x)) *scale_fn(cycle)\n    lr = tf.convert_to_tensor(lr)\n\n    return lr                \n</code></pre>\n\n<p>Below, the code is shown for using this in the actual Inception ResNet V2 model, my aim is to replace <code>tf_train_exponential_decay</code> with the Cyclic LR, which itself increases and decreases learning rate per step taken. </p>\n\n<pre><code>      iteration_step = 0 #(is increased every global_step)\n      lr1 = get_triangular_lr(iteration_step, stepsize, base_lr, max_lr)\n\n\n    #Define your exponentially decaying learning rate\n#         lr = tf.train.exponential_decay(\n#             learning_rate = initial_learning_rate,\n#             global_step = global_step,\n#             decay_steps = decay_steps,\n#             decay_rate = learning_rate_decay_factor,\n#             staircase = True)\n\n    #Now we can define the optimizer that takes on the learning rate\n\n    optimizer = tf.train.AdamOptimizer(learning_rate = lr1)\n\n    #Create the train_op.\n    train_op = slim.learning.create_train_op(total_loss, optimizer)\n</code></pre>\n\n<p>However, when I run the code above (by running the complete training model), the learning rate never gets increased by using that function. It only starts at <code>0.0001</code>, and every global_step taken it uses this value, while it should be increasing every global step (with the new value calculated by <code>get_triangular_lr</code>. I think it requires some kind of for-loop, but I can't figure out how exactly to implement it.</p>\n\n<pre><code>    #Now we need to create a training step function that runs both the \n    #train_op, metrics_op and updates the global_step concurrently.\n\n    def train_step(sess, train_op, global_step):\n        '''\n        Simply runs a session for the three arguments provided and gives a \n     logging on the time elapsed for each global step\n        '''\n        #Check the time for each sess run\n        start_time = time.time()\n        total_loss, global_step_count, _ = sess.run([train_op, global_step, \n        metrics_op])\n        time_elapsed = time.time() - start_time\n\n        #Run the logging to print some results\n        logging.info('global step %s: loss: %.4f (%.2f sec/step)', \n        global_step_count, total_loss, time_elapsed)\n\n        return total_loss, global_step_count\n</code></pre>\n\n<p>When I change the input of <code>train_op</code> to <code>total_loss, lr1</code> it gives me an AttributeError: 'Tensor' object has no attribute 'compute_gradients', and thus the model does not run at all. </p>\n\n<p><strong>EDIT: Have not yet found solution yet, but managed to use py.func, but now the next error occurs:</strong></p>\n\n<p>So I created <code>triangular_tf</code>, which uses <code>tf.py_func</code> to load the function, as follows:</p>\n\n<pre><code>triangular_tf = tf.py_func(get_triangular_lr, [iteration, stepsize, base_lr, max_lr], [tf.float64])\n</code></pre>\n\n<p>The only issue is, when I now pass <code>triangular_tf</code> to `optimizer = tf.train.AdamOptimizer(learning_rate = triangular_tf) the following error occurs:</p>\n\n<p><code>ValueError: cannot add op with name &lt;my weights variable name&gt;/Adam as that name is already used</code></p>\n\n<p>Not sure whether I still need the AdamOptimizer in this process, but I just simply need a way to adjust learning rate every step.</p>\n"
        },
        {
            "tags": [
                "php",
                "url",
                "path"
            ],
            "owner": {
                "reputation": 31,
                "user_id": 5914362,
                "user_type": "registered",
                "profile_image": "https://www.gravatar.com/avatar/d8c851957b7dd16f4fecd4b18a5c70c6?s=128&d=identicon&r=PG&f=1",
                "display_name": "J. Doe",
                "link": "https://stackoverflow.com/users/5914362/j-doe"
            },
            "is_answered": true,
            "view_count": 18,
            "accepted_answer_id": 50021264,
            "answer_count": 2,
            "score": 0,
            "last_activity_date": 1524658144,
            "creation_date": 1524651850,
            "last_edit_date": 1524656114,
            "question_id": 50019860,
            "body_markdown": "I have a simple strange problem but I can not find a function to do this after many search.\r\n\r\nI have an URL like `http://example.com/folder/folder2/../image/test.jpg` and I would like a function which return the correct absolute link:\r\n\r\n    http://example.com/folder/image/test.jpg\r\n\r\nA function with only one param, the url (and not base dir or relative dir like in examples I found)\r\n\r\nIf you can help me, thanks.\r\n",
            "link": "https://stackoverflow.com/questions/50019860/php-convert-absolute-url-containing-relative-paths-in-absolute-url-without-relat",
            "title": "php convert absolute URL containing relative paths in absolute url without relative path",
            "body": "<p>I have a simple strange problem but I can not find a function to do this after many search.</p>\n\n<p>I have an URL like <code>http://example.com/folder/folder2/../image/test.jpg</code> and I would like a function which return the correct absolute link:</p>\n\n<pre><code>http://example.com/folder/image/test.jpg\n</code></pre>\n\n<p>A function with only one param, the url (and not base dir or relative dir like in examples I found)</p>\n\n<p>If you can help me, thanks.</p>\n"
        },
        {
            "tags": [
                "c++"
            ],
            "owner": {
                "reputation": 1,
                "user_id": 9697222,
                "user_type": "registered",
                "profile_image": "https://lh3.googleusercontent.com/-PTMIdtQejoY/AAAAAAAAAAI/AAAAAAAAA9Y/4huQtQuW27Q/photo.jpg?sz=128",
                "display_name": "Sudharsan Srinivasan",
                "link": "https://stackoverflow.com/users/9697222/sudharsan-srinivasan"
            },
            "is_answered": false,
            "view_count": 45,
            "closed_date": 1524658476,
            "answer_count": 0,
            "score": -7,
            "last_activity_date": 1524658142,
            "creation_date": 1524658142,
            "question_id": 50021965,
            "body_markdown": "Let&#39;s say I have a C++ code with a 3D array A[50][10][10]. Inside for loop &#39;A&#39; gets updated for every time step. I have two question now.\r\n\r\n1. Let&#39;s say if I ran the loop for 1000 iterations, I want to save values of &#39;A&#39; into my computer for every 100th iteration.\r\n2. Also, after the iteration is finished I want to save the final values of &#39;A&#39; into my computer. \r\n\r\nHow can I code this in C++ ? \r\n\r\nThank you",
            "link": "https://stackoverflow.com/questions/50021965/saving-a-3d-array-into-computer",
            "closed_reason": "too broad",
            "title": "Saving a 3D array into computer",
            "body": "<p>Let's say I have a C++ code with a 3D array A[50][10][10]. Inside for loop 'A' gets updated for every time step. I have two question now.</p>\n\n<ol>\n<li>Let's say if I ran the loop for 1000 iterations, I want to save values of 'A' into my computer for every 100th iteration.</li>\n<li>Also, after the iteration is finished I want to save the final values of 'A' into my computer. </li>\n</ol>\n\n<p>How can I code this in C++ ? </p>\n\n<p>Thank you</p>\n"
        },
        {
            "tags": [
                "php",
                "object-oriented-analysis"
            ],
            "owner": {
                "reputation": 473,
                "user_id": 390386,
                "user_type": "registered",
                "profile_image": "https://www.gravatar.com/avatar/a206c93a1df8ceb4aa63342cf5a51a5b?s=128&d=identicon&r=PG",
                "display_name": "Waqas",
                "link": "https://stackoverflow.com/users/390386/waqas"
            },
            "is_answered": true,
            "view_count": 69,
            "accepted_answer_id": 50009215,
            "answer_count": 3,
            "score": -1,
            "last_activity_date": 1524658140,
            "creation_date": 1524596600,
            "question_id": 50009108,
            "body_markdown": "In PHP, I have an abstract class (parent) which is extended by the child class. I want the child class to implement a function of parent. And when I call the implemented function of child, a default functionality of parent should be invoked automatically. \r\nIs it possible?\r\n\r\nFor example, I want to create parent&#39;s log function every time a send function of child is invoked.\r\n\r\n    abstract class CommunicationService {\r\n        // child classes must implement this\r\n        abstract function send();\r\n        abstract function receive();\r\n\r\n        public function log($action) {\r\n            echo &#39;Creating nice Log on = &#39; . $action;\r\n        }\r\n    }\r\n\r\n    class ServiceA extends CommunicationService {\r\n        public function send() {\r\n        \t// Is it possible that the parent&#39;s logging functionality be invoked automatically by default?\r\n            echo &#39;Send Message using Service A&#39;;\r\n        }\r\n        public function receive() {\r\n            echo &#39;Receive Message using Service A&#39;;\r\n        }\r\n    }\r\n\r\n    $serviceA = new ServiceA();\r\n    $serviceA-&gt;send(); // It should send message as well as create logs.\r\n    $serviceA-&gt;receive(); // It should just receive message and not log it.\r\n\r\nAlso, is it possible to perform some default action in parent and the rest of the functionality in child?\r\n\r\nbest regards.",
            "link": "https://stackoverflow.com/questions/50009108/oop-how-to-make-a-parent-function-perform-some-default-functionality",
            "title": "OOP - How to make a parent function perform some default functionality?",
            "body": "<p>In PHP, I have an abstract class (parent) which is extended by the child class. I want the child class to implement a function of parent. And when I call the implemented function of child, a default functionality of parent should be invoked automatically. \nIs it possible?</p>\n\n<p>For example, I want to create parent's log function every time a send function of child is invoked.</p>\n\n<pre><code>abstract class CommunicationService {\n    // child classes must implement this\n    abstract function send();\n    abstract function receive();\n\n    public function log($action) {\n        echo 'Creating nice Log on = ' . $action;\n    }\n}\n\nclass ServiceA extends CommunicationService {\n    public function send() {\n        // Is it possible that the parent's logging functionality be invoked automatically by default?\n        echo 'Send Message using Service A';\n    }\n    public function receive() {\n        echo 'Receive Message using Service A';\n    }\n}\n\n$serviceA = new ServiceA();\n$serviceA-&gt;send(); // It should send message as well as create logs.\n$serviceA-&gt;receive(); // It should just receive message and not log it.\n</code></pre>\n\n<p>Also, is it possible to perform some default action in parent and the rest of the functionality in child?</p>\n\n<p>best regards.</p>\n"
        },
        {
            "tags": [
                "php",
                "html",
                "css"
            ],
            "owner": {
                "reputation": 11,
                "user_id": 9689901,
                "user_type": "registered",
                "profile_image": "https://lh3.googleusercontent.com/-XdUIqdMkCWA/AAAAAAAAAAI/AAAAAAAAAAA/4252rscbv5M/photo.jpg?sz=128",
                "display_name": "Ruben",
                "link": "https://stackoverflow.com/users/9689901/ruben"
            },
            "is_answered": true,
            "view_count": 57,
            "answer_count": 4,
            "score": 1,
            "last_activity_date": 1524658138,
            "creation_date": 1524656320,
            "last_edit_date": 1524656846,
            "question_id": 50021348,
            "body_markdown": "Here is part of the code I am working on. All this has to do is, if the ping succeeds it changes the first td to green but if the ping failed its red. \r\n\r\nThe problem I&#39;m having is that I can use images or any kind of method to display it and it works but all I want is to change the `background-color` of the `td` before the IP address. Am I doing something wrong here?\r\n\r\n    &lt;table  height=&quot;630&quot; class=&quot;table&quot;&gt;\r\n        &lt;tr&gt;\r\n            &lt;td width=&quot;5&quot; &gt;\r\n            &lt;?php\r\n                $str = exec(&quot;ping -n 1 -w 1 10.9.1.1&quot;, $input, $result);\r\n                if ($result == 0){ echo &quot;&lt;style=&#39;background-color:green;&#39;&gt;&quot;;}\r\n                else{ echo &quot;&lt;style=&#39;background-color:red;&#39;&gt;&quot;;}\r\n            ?&gt;\r\n            &lt;/td&gt;\r\n            &lt;td width=&quot;50&quot;&gt;10.9.1.1&lt;/td&gt;\r\n        &lt;/tr&gt;\r\n    &lt;/table&gt;\r\n",
            "link": "https://stackoverflow.com/questions/50021348/td-changes-color-on-echo-result",
            "title": "td changes color on echo result",
            "body": "<p>Here is part of the code I am working on. All this has to do is, if the ping succeeds it changes the first td to green but if the ping failed its red. </p>\n\n<p>The problem I'm having is that I can use images or any kind of method to display it and it works but all I want is to change the <code>background-color</code> of the <code>td</code> before the IP address. Am I doing something wrong here?</p>\n\n<pre><code>&lt;table  height=\"630\" class=\"table\"&gt;\n    &lt;tr&gt;\n        &lt;td width=\"5\" &gt;\n        &lt;?php\n            $str = exec(\"ping -n 1 -w 1 10.9.1.1\", $input, $result);\n            if ($result == 0){ echo \"&lt;style='background-color:green;'&gt;\";}\n            else{ echo \"&lt;style='background-color:red;'&gt;\";}\n        ?&gt;\n        &lt;/td&gt;\n        &lt;td width=\"50\"&gt;10.9.1.1&lt;/td&gt;\n    &lt;/tr&gt;\n&lt;/table&gt;\n</code></pre>\n"
        },
        {
            "tags": [
                "jsp",
                "internationalization",
                "language-translation"
            ],
            "owner": {
                "reputation": 1,
                "user_id": 9696624,
                "user_type": "registered",
                "profile_image": "https://www.gravatar.com/avatar/e75509279387d060e306f9362521a836?s=128&d=identicon&r=PG&f=1",
                "display_name": "Abi",
                "link": "https://stackoverflow.com/users/9696624/abi"
            },
            "is_answered": false,
            "view_count": 7,
            "answer_count": 0,
            "score": 0,
            "last_activity_date": 1524658132,
            "creation_date": 1524651547,
            "last_edit_date": 1524658132,
            "question_id": 50019748,
            "body_markdown": "I need to find out a way for all the hard coded values in JSP which needs to be moved out to properties file for internationalization support. But this is a huge code base finding it manually is tough, any idea for any automated way to find those out. Help is highly appreciated.\r\n\r\nThanks.",
            "link": "https://stackoverflow.com/questions/50019748/hardcoded-strings-in-jsp",
            "title": "hardcoded strings in JSP",
            "body": "<p>I need to find out a way for all the hard coded values in JSP which needs to be moved out to properties file for internationalization support. But this is a huge code base finding it manually is tough, any idea for any automated way to find those out. Help is highly appreciated.</p>\n\n<p>Thanks.</p>\n"
        },
        {
            "tags": [
                "sql"
            ],
            "owner": {
                "reputation": 251,
                "user_id": 3338349,
                "user_type": "registered",
                "profile_image": "https://i.stack.imgur.com/i8GKo.jpg?s=128&g=1",
                "display_name": "MickelsonMichael",
                "link": "https://stackoverflow.com/users/3338349/mickelsonmichael"
            },
            "is_answered": false,
            "view_count": 25,
            "closed_date": 1524658434,
            "answer_count": 0,
            "score": 2,
            "last_activity_date": 1524658131,
            "creation_date": 1524658131,
            "question_id": 50021958,
            "body_markdown": "Yesterday I needed to make updates to a database changing some user roles and removing some others, so I made a query and one of the lines was this:\r\n\r\n    DELETE FROM [UserRoles]\r\n    WHERE RoleId = (SELECT RoleId FROM Roles WHERE Name = &#39;Rolename&#39;)\r\n\r\n\r\nNow I made an error in the SELECT statement. It should have been `SELECT Id` and not `SELECT RoleId`; the Roles table doesn&#39;t have a column for `RoleId` it is just `Id`. When I ran the script, instead of failing, it continued to delete *all* UserRoles (luckily I was on a test database). **Why didn&#39;t the query fail? What did the Select return to match `RoleId` to everything?**\r\n",
            "link": "https://stackoverflow.com/questions/50021958/why-does-a-sql-query-continue-if-a-select-statement-within-a-where-is-incorrect",
            "closed_reason": "duplicate",
            "title": "Why does a SQL Query continue if a SELECT statement within a WHERE is incorrect",
            "body": "<p>Yesterday I needed to make updates to a database changing some user roles and removing some others, so I made a query and one of the lines was this:</p>\n\n<pre><code>DELETE FROM [UserRoles]\nWHERE RoleId = (SELECT RoleId FROM Roles WHERE Name = 'Rolename')\n</code></pre>\n\n<p>Now I made an error in the SELECT statement. It should have been <code>SELECT Id</code> and not <code>SELECT RoleId</code>; the Roles table doesn't have a column for <code>RoleId</code> it is just <code>Id</code>. When I ran the script, instead of failing, it continued to delete <em>all</em> UserRoles (luckily I was on a test database). <strong>Why didn't the query fail? What did the Select return to match <code>RoleId</code> to everything?</strong></p>\n"
        },
        {
            "tags": [
                "c#",
                "amazon-web-services",
                "amazon-s3",
                "uwp"
            ],
            "owner": {
                "reputation": 32,
                "user_id": 9342407,
                "user_type": "registered",
                "profile_image": "https://www.gravatar.com/avatar/962518a0f5541d69ea410047f22bf85d?s=128&d=identicon&r=PG&f=1",
                "display_name": "Karel_cz",
                "link": "https://stackoverflow.com/users/9342407/karel-cz"
            },
            "is_answered": false,
            "view_count": 21,
            "answer_count": 1,
            "score": -1,
            "last_activity_date": 1524658129,
            "creation_date": 1524657461,
            "last_edit_date": 1524657547,
            "question_id": 50021747,
            "body_markdown": "I have this code:\r\n\r\n    try\r\n    {\r\n        TransferUtility fileTransferUtility = new TransferUtility(new AmazonS3Client(S3AccessId, S3SecretKey, Amazon.RegionEndpoint.USEast1));\r\n\r\n        // Use TransferUtilityUploadRequest to configure options.\r\n        TransferUtilityUploadRequest uploadRequest =\r\n            new TransferUtilityUploadRequest\r\n            {\r\n                BucketName = S3BucketName,\r\n                InputStream = streamx,\r\n                Key = S3FileKey                                              \r\n            };\r\n\r\n        uploadRequest.UploadProgressEvent += new EventHandler&lt;UploadProgressArgs&gt;(uploadRequest_UploadPartProgressEvent);\r\n        \r\n        await fileTransferUtility.UploadAsync(uploadRequest);\r\n        Debug.WriteLine(&quot;Upload completed&quot;);\r\n\r\n            \r\n    }\r\n\r\n    catch (AmazonS3Exception exception)\r\n    {\r\n        Debug.WriteLine(exception.Message, exception.InnerException);\r\n       \r\n\r\n    }\r\n\r\nAnd I need to update upload progress in generated item in ListView. In this ListView can be multiple items. Any idea?",
            "link": "https://stackoverflow.com/questions/50021747/progress-bar-by-s3-upload",
            "title": "Progress bar by S3 upload",
            "body": "<p>I have this code:</p>\n\n<pre><code>try\n{\n    TransferUtility fileTransferUtility = new TransferUtility(new AmazonS3Client(S3AccessId, S3SecretKey, Amazon.RegionEndpoint.USEast1));\n\n    // Use TransferUtilityUploadRequest to configure options.\n    TransferUtilityUploadRequest uploadRequest =\n        new TransferUtilityUploadRequest\n        {\n            BucketName = S3BucketName,\n            InputStream = streamx,\n            Key = S3FileKey                                              \n        };\n\n    uploadRequest.UploadProgressEvent += new EventHandler&lt;UploadProgressArgs&gt;(uploadRequest_UploadPartProgressEvent);\n\n    await fileTransferUtility.UploadAsync(uploadRequest);\n    Debug.WriteLine(\"Upload completed\");\n\n\n}\n\ncatch (AmazonS3Exception exception)\n{\n    Debug.WriteLine(exception.Message, exception.InnerException);\n\n\n}\n</code></pre>\n\n<p>And I need to update upload progress in generated item in ListView. In this ListView can be multiple items. Any idea?</p>\n"
        },
        {
            "tags": [
                "java",
                "maven",
                "xsd",
                "jaxb",
                "xsd-1.0"
            ],
            "owner": {
                "reputation": 7733,
                "user_id": 289011,
                "user_type": "registered",
                "accept_rate": 97,
                "profile_image": "https://www.gravatar.com/avatar/7fabc4413849953957908f8690c2c24c?s=128&d=identicon&r=PG",
                "display_name": "BorrajaX",
                "link": "https://stackoverflow.com/users/289011/borrajax"
            },
            "is_answered": true,
            "view_count": 341,
            "accepted_answer_id": 32897006,
            "answer_count": 1,
            "score": 3,
            "last_activity_date": 1524658124,
            "creation_date": 1443713000,
            "last_edit_date": 1524658124,
            "question_id": 32891300,
            "body_markdown": "In my Java (Maven) project I&#39;m using [JAXB 2.2.11][1] to rebuild instances of a class from an XML payload received by our servers. I have an `.xsd` schema defining the class, which works great in conjunction with JAXB to rebuild an instance of the type I want. The issue I&#39;m having is that those payloads can (without any notice or warning) have extra elements which I don&#39;t really care about.\r\n\r\nOne of the places where those extra elements can appear is within an `xs:all` tag. I do like having the functionality of said [`xs:all`][2] tag:\r\n\r\n&gt; The all element specifies that the child elements can appear in any\r\n&gt; order and that each child element can occur zero or one time.\r\n\r\nHowever, I don&#39;t want to get a parsing error while processing an XML payload that contains extra attributes. An `xs:any` tag inside the `xs:all` would work great, but it&#39;s not permitted in XSD 1.0 (according to [w3schools][3] and this other [SO answer][4]) and apparently, JAXB doesn&#39;t support XSD 1.1. Also, the way `JAXB` treats the `any` or the `anyAttribute` is very interesting, because it puts all the unknown nodes into a map, so I can log it saying *&quot;Hey! We are receiving an attribute that we don&#39;t really care about as of now, but maybe you&#39;ll find it somehow useful in the future?&quot;*\r\n\r\nI&#39;ve read about [Xsom][5], that supports XSD 1.1, but apparently, it doesn&#39;t return an *instance* of the class you want, but more generic set of hash-maps and lists, therefore losing my type checking, which is something I don&#39;t want to.\r\n\r\nSo... Is there any way of *pretending* to have an `xs:any` within an `xs:all`?\r\n\r\n\r\n  [1]: https://jaxb.java.net/\r\n  [2]: http://www.w3schools.com/schema/el_all.asp\r\n  [3]: http://www.w3schools.com/schema/el_sequence.asp &quot;w3schools&quot;\r\n  [4]: https://stackoverflow.com/a/3367162/289011\r\n  [5]: https://xsom.java.net/",
            "link": "https://stackoverflow.com/questions/32891300/xsany-inside-an-xsall-xsd-1-0-workarounds",
            "title": "&lt;xs:any&gt; inside an &lt;xs:all&gt; XSD 1.0 workarounds?",
            "body": "<p>In my Java (Maven) project I'm using <a href=\"https://jaxb.java.net/\" rel=\"nofollow noreferrer\">JAXB 2.2.11</a> to rebuild instances of a class from an XML payload received by our servers. I have an <code>.xsd</code> schema defining the class, which works great in conjunction with JAXB to rebuild an instance of the type I want. The issue I'm having is that those payloads can (without any notice or warning) have extra elements which I don't really care about.</p>\n\n<p>One of the places where those extra elements can appear is within an <code>xs:all</code> tag. I do like having the functionality of said <a href=\"http://www.w3schools.com/schema/el_all.asp\" rel=\"nofollow noreferrer\"><code>xs:all</code></a> tag:</p>\n\n<blockquote>\n  <p>The all element specifies that the child elements can appear in any\n  order and that each child element can occur zero or one time.</p>\n</blockquote>\n\n<p>However, I don't want to get a parsing error while processing an XML payload that contains extra attributes. An <code>xs:any</code> tag inside the <code>xs:all</code> would work great, but it's not permitted in XSD 1.0 (according to <a href=\"http://www.w3schools.com/schema/el_sequence.asp\" rel=\"nofollow noreferrer\" title=\"w3schools\">w3schools</a> and this other <a href=\"https://stackoverflow.com/a/3367162/289011\">SO answer</a>) and apparently, JAXB doesn't support XSD 1.1. Also, the way <code>JAXB</code> treats the <code>any</code> or the <code>anyAttribute</code> is very interesting, because it puts all the unknown nodes into a map, so I can log it saying <em>\"Hey! We are receiving an attribute that we don't really care about as of now, but maybe you'll find it somehow useful in the future?\"</em></p>\n\n<p>I've read about <a href=\"https://xsom.java.net/\" rel=\"nofollow noreferrer\">Xsom</a>, that supports XSD 1.1, but apparently, it doesn't return an <em>instance</em> of the class you want, but more generic set of hash-maps and lists, therefore losing my type checking, which is something I don't want to.</p>\n\n<p>So... Is there any way of <em>pretending</em> to have an <code>xs:any</code> within an <code>xs:all</code>?</p>\n"
        },
        {
            "tags": [
                "c#",
                "ms-word"
            ],
            "owner": {
                "reputation": 49,
                "user_id": 9623930,
                "user_type": "registered",
                "profile_image": "https://www.gravatar.com/avatar/f17bbde308e44712367ec2c80270d5ef?s=128&d=identicon&r=PG&f=1",
                "display_name": "Gudra",
                "link": "https://stackoverflow.com/users/9623930/gudra"
            },
            "is_answered": false,
            "view_count": 42,
            "answer_count": 0,
            "score": -2,
            "last_activity_date": 1524658124,
            "creation_date": 1524656395,
            "last_edit_date": 1524658124,
            "question_id": 50021377,
            "body_markdown": "So, I have a document that look like this\r\n\r\n    Dear Stack Overflow\r\n    \r\n    \r\n    I love you\r\n    \r\n    \r\n    With love, Gudra\r\n    \r\n    \r\n    \r\n    \r\n    \r\n    \r\n    .\r\n\r\nbut without the end dot. There are a lot of empty lines at the end of the document, lines that aren&#39;t useful. I want to delete them programaticaly, to trim the document, from a C# console application, but without deleting other multiple empty lines in the middle of the document. How could I do it?\r\n\r\n\r\n    Word.Document wordDoc = wordApp.Documents.Open(docPath);\r\n    // TODO: trim it\r\n    Word.Paragraphs pars = wordDoc.Paragraphs;\r\n    Word.Paragraph par = null;\r\n    while ((par = pars.Last).Range.Text == &quot;&quot;) par.Range.Delete();\r\n\r\n    wordDoc.Save();\r\n    wordDoc.Close();\r\n    wordApp.Quit();\r\n\r\nThis is what I tried. Keep deleting the last paragraph until it contains some text, but it doesn&#39;t seems to work.",
            "link": "https://stackoverflow.com/questions/50021377/trim-a-word-document-end-empty-lines",
            "title": "Trim a Word Document end empty lines",
            "body": "<p>So, I have a document that look like this</p>\n\n<pre><code>Dear Stack Overflow\n\n\nI love you\n\n\nWith love, Gudra\n\n\n\n\n\n\n.\n</code></pre>\n\n<p>but without the end dot. There are a lot of empty lines at the end of the document, lines that aren't useful. I want to delete them programaticaly, to trim the document, from a C# console application, but without deleting other multiple empty lines in the middle of the document. How could I do it?</p>\n\n<pre><code>Word.Document wordDoc = wordApp.Documents.Open(docPath);\n// TODO: trim it\nWord.Paragraphs pars = wordDoc.Paragraphs;\nWord.Paragraph par = null;\nwhile ((par = pars.Last).Range.Text == \"\") par.Range.Delete();\n\nwordDoc.Save();\nwordDoc.Close();\nwordApp.Quit();\n</code></pre>\n\n<p>This is what I tried. Keep deleting the last paragraph until it contains some text, but it doesn't seems to work.</p>\n"
        },
        {
            "tags": [
                "python",
                "xpath",
                "web-scraping",
                "web-crawler",
                "scrapy-spider"
            ],
            "owner": {
                "reputation": 4,
                "user_id": 9593060,
                "user_type": "registered",
                "profile_image": "https://graph.facebook.com/1892710857405653/picture?type=large",
                "display_name": "Mattia Surricchio",
                "link": "https://stackoverflow.com/users/9593060/mattia-surricchio"
            },
            "is_answered": true,
            "view_count": 38,
            "accepted_answer_id": 50016305,
            "answer_count": 2,
            "score": 0,
            "last_activity_date": 1524658121,
            "creation_date": 1524606371,
            "last_edit_date": 1524658121,
            "question_id": 50011155,
            "body_markdown": "I&#39;m trying to crawl a website (I got their authorization), and my code returns what I want in scrapy shell, but I get nothing in my spider.\r\n\r\nI also checked all the previous question similar to this one without any success, e.g., the website doesn&#39;t use javascript in the home page to load the elements I need.\r\n\r\n    import scrapy\r\n\r\n\r\n    class MySpider(scrapy.Spider):\r\n        name = &#39;MySpider&#39;\r\n       \r\n        start_urls = [ #WRONG URL, SHOULD BE https://shop.app4health.it/ PROBLEM SOLVED!\r\n            &#39;https://www.app4health.it/&#39;,\r\n        ]\r\n      \r\n        def parse(self, response):\r\n            self.logger.info(&#39;A response from %s just arrived!&#39;, response.url)\r\n            print (&#39;PRE RISULTATI&#39;)\r\n            \r\n            results =  response.selector.xpath(&#39;//*[@id=&quot;nav&quot;]/ol/li[*]/a/@href&#39;).extract()\r\n            # results = response.css(&#39;li a&gt;href&#39;).extract()\r\n            \r\n            \r\n            # This works on scrapy shell, not in code\r\n            #risultati =  response.xpath(&#39;//*[@id=&quot;nav&quot;]/ol/li[1]/a&#39;).extract()\r\n            print (risultati)\r\n           \r\n           \r\n           \r\n          \r\n            #for pagineitems in risultati:\r\n                   # next_page = pagineitems \r\n            print (&#39;NEXT PAGE&#39;)\r\n            #Ignores the request cause already done. Insert dont filter\r\n            yield scrapy.Request(url=risultati, callback=self.prodotti,dont_filter = True)\r\n        \r\n        def prodotti(self, response):\r\n            self.logger.info(&#39;A REEEESPONSEEEEEE from %s just arrived!&#39;, response.url)\r\n            return 1\r\n\r\nThe website i&#39;m trying to crawl is https://shop.app4health.it/ \r\n\r\nThe xpath command that i use is this one : \r\n\r\n    response.selector.xpath(&#39;//*[@id=&quot;nav&quot;]/ol/li[*]/a/@href&#39;).extract()\r\n\r\nI know there are some problems with the **prodotti** function ecc..., but that&#39;s not the point. I would like to understand why the xpath selector works with scrapy shell ( i get exactly the links that i need ), but when i run it in my spider, i always get a null list.\r\n\r\nIf it can help, when i use CSS selectors in my spider, it works fine and it finds the elements, but i would like to use xpath ( i need it in the future development of my application ).\r\n\r\nThanks for the help :) \r\n\r\n**EDIT**:\r\nI tried to print the body of the first response ( from start_urls ) and it&#39;s correct, i get the page i want. When i use selectors in my code ( even the one that have been suggested ) they all work fine in shell, but i get nothing in my code! \r\n\r\n**SOLVED**:\r\nPath is correct. I wrote the wrong start_urls! \r\n",
            "link": "https://stackoverflow.com/questions/50011155/scrapy-xpath-works-in-shell-but-not-in-code",
            "title": "Scrapy - Xpath works in shell but not in code",
            "body": "<p>I'm trying to crawl a website (I got their authorization), and my code returns what I want in scrapy shell, but I get nothing in my spider.</p>\n\n<p>I also checked all the previous question similar to this one without any success, e.g., the website doesn't use javascript in the home page to load the elements I need.</p>\n\n<pre><code>import scrapy\n\n\nclass MySpider(scrapy.Spider):\n    name = 'MySpider'\n\n    start_urls = [ #WRONG URL, SHOULD BE https://shop.app4health.it/ PROBLEM SOLVED!\n        'https://www.app4health.it/',\n    ]\n\n    def parse(self, response):\n        self.logger.info('A response from %s just arrived!', response.url)\n        print ('PRE RISULTATI')\n\n        results =  response.selector.xpath('//*[@id=\"nav\"]/ol/li[*]/a/@href').extract()\n        # results = response.css('li a&gt;href').extract()\n\n\n        # This works on scrapy shell, not in code\n        #risultati =  response.xpath('//*[@id=\"nav\"]/ol/li[1]/a').extract()\n        print (risultati)\n\n\n\n\n        #for pagineitems in risultati:\n               # next_page = pagineitems \n        print ('NEXT PAGE')\n        #Ignores the request cause already done. Insert dont filter\n        yield scrapy.Request(url=risultati, callback=self.prodotti,dont_filter = True)\n\n    def prodotti(self, response):\n        self.logger.info('A REEEESPONSEEEEEE from %s just arrived!', response.url)\n        return 1\n</code></pre>\n\n<p>The website i'm trying to crawl is <a href=\"https://shop.app4health.it/\" rel=\"nofollow noreferrer\">https://shop.app4health.it/</a> </p>\n\n<p>The xpath command that i use is this one : </p>\n\n<pre><code>response.selector.xpath('//*[@id=\"nav\"]/ol/li[*]/a/@href').extract()\n</code></pre>\n\n<p>I know there are some problems with the <strong>prodotti</strong> function ecc..., but that's not the point. I would like to understand why the xpath selector works with scrapy shell ( i get exactly the links that i need ), but when i run it in my spider, i always get a null list.</p>\n\n<p>If it can help, when i use CSS selectors in my spider, it works fine and it finds the elements, but i would like to use xpath ( i need it in the future development of my application ).</p>\n\n<p>Thanks for the help :) </p>\n\n<p><strong>EDIT</strong>:\nI tried to print the body of the first response ( from start_urls ) and it's correct, i get the page i want. When i use selectors in my code ( even the one that have been suggested ) they all work fine in shell, but i get nothing in my code! </p>\n\n<p><strong>SOLVED</strong>:\nPath is correct. I wrote the wrong start_urls! </p>\n"
        }
    ],
    "has_more": true,
    "quota_max": 300,
    "quota_remaining": 132
}